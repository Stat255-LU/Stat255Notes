<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Predictive Modeling – STAT 255 Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch6.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Ch7.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Predictive Modeling</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">STAT 255 Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Visualizing and Summarizing Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Statistical Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation-Based Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Inference from Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Building and Assessing Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch7.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Predictive Modeling</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learning-outcomes" id="toc-learning-outcomes" class="nav-link active" data-scroll-target="#learning-outcomes">Learning Outcomes</a></li>
  <li><a href="#modeling-for-prediction" id="toc-modeling-for-prediction" class="nav-link" data-scroll-target="#modeling-for-prediction"><span class="header-section-number">7.1</span> Modeling for Prediction</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview"><span class="header-section-number">7.1.1</span> Overview</a></li>
  <li><a href="#illustration-of-predictive-modeling" id="toc-illustration-of-predictive-modeling" class="nav-link" data-scroll-target="#illustration-of-predictive-modeling"><span class="header-section-number">7.1.2</span> Illustration of Predictive Modeling</a></li>
  <li><a href="#predicting-new-data" id="toc-predicting-new-data" class="nav-link" data-scroll-target="#predicting-new-data"><span class="header-section-number">7.1.3</span> Predicting New Data</a></li>
  <li><a href="#prediction-error" id="toc-prediction-error" class="nav-link" data-scroll-target="#prediction-error"><span class="header-section-number">7.1.4</span> Prediction Error</a></li>
  <li><a href="#variance-bias-tradeoff" id="toc-variance-bias-tradeoff" class="nav-link" data-scroll-target="#variance-bias-tradeoff"><span class="header-section-number">7.1.5</span> Variance Bias Tradeoff</a></li>
  </ul></li>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation"><span class="header-section-number">7.2</span> Cross-Validation</a>
  <ul class="collapse">
  <li><a href="#cross-validation-illustration" id="toc-cross-validation-illustration" class="nav-link" data-scroll-target="#cross-validation-illustration"><span class="header-section-number">7.2.1</span> Cross-Validation Illustration</a></li>
  <li><a href="#ames-housing-data" id="toc-ames-housing-data" class="nav-link" data-scroll-target="#ames-housing-data"><span class="header-section-number">7.2.2</span> Ames Housing Data</a></li>
  <li><a href="#cross-validation-with-caret" id="toc-cross-validation-with-caret" class="nav-link" data-scroll-target="#cross-validation-with-caret"><span class="header-section-number">7.2.3</span> Cross-Validation with <code>caret</code></a></li>
  </ul></li>
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression"><span class="header-section-number">7.3</span> Ridge Regression</a>
  <ul class="collapse">
  <li><a href="#complexity-in-model-coefficients" id="toc-complexity-in-model-coefficients" class="nav-link" data-scroll-target="#complexity-in-model-coefficients"><span class="header-section-number">7.3.1</span> Complexity in Model Coefficients</a></li>
  <li><a href="#ridge-regression-penalty" id="toc-ridge-regression-penalty" class="nav-link" data-scroll-target="#ridge-regression-penalty"><span class="header-section-number">7.3.2</span> Ridge Regression Penalty</a></li>
  <li><a href="#choosing-lambda" id="toc-choosing-lambda" class="nav-link" data-scroll-target="#choosing-lambda"><span class="header-section-number">7.3.3</span> Choosing <span class="math inline">\(\lambda\)</span></a></li>
  <li><a href="#ridge-regression-on-housing-dataset" id="toc-ridge-regression-on-housing-dataset" class="nav-link" data-scroll-target="#ridge-regression-on-housing-dataset"><span class="header-section-number">7.3.4</span> Ridge Regression on Housing Dataset</a></li>
  <li><a href="#ridge-vs-ols" id="toc-ridge-vs-ols" class="nav-link" data-scroll-target="#ridge-vs-ols"><span class="header-section-number">7.3.5</span> Ridge vs OLS</a></li>
  <li><a href="#lasso-and-elastic-net" id="toc-lasso-and-elastic-net" class="nav-link" data-scroll-target="#lasso-and-elastic-net"><span class="header-section-number">7.3.6</span> Lasso and Elastic Net</a></li>
  </ul></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees"><span class="header-section-number">7.4</span> Decision Trees</a>
  <ul class="collapse">
  <li><a href="#basics-of-decision-trees" id="toc-basics-of-decision-trees" class="nav-link" data-scroll-target="#basics-of-decision-trees"><span class="header-section-number">7.4.1</span> Basics of Decision Trees</a></li>
  <li><a href="#partitioning-in-a-decision-tree" id="toc-partitioning-in-a-decision-tree" class="nav-link" data-scroll-target="#partitioning-in-a-decision-tree"><span class="header-section-number">7.4.2</span> Partitioning in A Decision Tree</a></li>
  <li><a href="#next-splits" id="toc-next-splits" class="nav-link" data-scroll-target="#next-splits"><span class="header-section-number">7.4.3</span> Next Splits</a></li>
  <li><a href="#recursive-partitioning" id="toc-recursive-partitioning" class="nav-link" data-scroll-target="#recursive-partitioning"><span class="header-section-number">7.4.4</span> Recursive Partitioning</a></li>
  <li><a href="#model-complexity-in-trees" id="toc-model-complexity-in-trees" class="nav-link" data-scroll-target="#model-complexity-in-trees"><span class="header-section-number">7.4.5</span> Model Complexity in Trees</a></li>
  <li><a href="#cross-validation-on-housing-data" id="toc-cross-validation-on-housing-data" class="nav-link" data-scroll-target="#cross-validation-on-housing-data"><span class="header-section-number">7.4.6</span> Cross-Validation on Housing Data</a></li>
  <li><a href="#comparing-ols-lasso-ridge-and-tree" id="toc-comparing-ols-lasso-ridge-and-tree" class="nav-link" data-scroll-target="#comparing-ols-lasso-ridge-and-tree"><span class="header-section-number">7.4.7</span> Comparing OLS, Lasso, Ridge, and Tree</a></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest"><span class="header-section-number">7.4.8</span> Random Forest</a></li>
  </ul></li>
  <li><a href="#regression-splines" id="toc-regression-splines" class="nav-link" data-scroll-target="#regression-splines"><span class="header-section-number">7.5</span> Regression Splines</a>
  <ul class="collapse">
  <li><a href="#regression-splines-1" id="toc-regression-splines-1" class="nav-link" data-scroll-target="#regression-splines-1"><span class="header-section-number">7.5.1</span> Regression Splines</a></li>
  <li><a href="#two-models-with-high-bias" id="toc-two-models-with-high-bias" class="nav-link" data-scroll-target="#two-models-with-high-bias"><span class="header-section-number">7.5.2</span> Two Models with High Bias</a></li>
  <li><a href="#cubic-splines" id="toc-cubic-splines" class="nav-link" data-scroll-target="#cubic-splines"><span class="header-section-number">7.5.3</span> Cubic Splines</a></li>
  <li><a href="#predicting-test-data" id="toc-predicting-test-data" class="nav-link" data-scroll-target="#predicting-test-data"><span class="header-section-number">7.5.4</span> Predicting Test Data</a></li>
  <li><a href="#implementation-of-splines" id="toc-implementation-of-splines" class="nav-link" data-scroll-target="#implementation-of-splines"><span class="header-section-number">7.5.5</span> Implementation of Splines</a></li>
  </ul></li>
  <li><a href="#assessing-a-classifiers-performance" id="toc-assessing-a-classifiers-performance" class="nav-link" data-scroll-target="#assessing-a-classifiers-performance"><span class="header-section-number">7.6</span> Assessing a Classifier’s Performance</a>
  <ul class="collapse">
  <li><a href="#measuring-prediction-accuracy" id="toc-measuring-prediction-accuracy" class="nav-link" data-scroll-target="#measuring-prediction-accuracy"><span class="header-section-number">7.6.1</span> Measuring Prediction Accuracy</a></li>
  <li><a href="#decision-tree-classifier" id="toc-decision-tree-classifier" class="nav-link" data-scroll-target="#decision-tree-classifier"><span class="header-section-number">7.6.2</span> Decision Tree Classifier</a></li>
  <li><a href="#assessing-classifier-accuracy" id="toc-assessing-classifier-accuracy" class="nav-link" data-scroll-target="#assessing-classifier-accuracy"><span class="header-section-number">7.6.3</span> Assessing Classifier Accuracy</a></li>
  <li><a href="#confusion-matrix" id="toc-confusion-matrix" class="nav-link" data-scroll-target="#confusion-matrix"><span class="header-section-number">7.6.4</span> Confusion Matrix</a></li>
  <li><a href="#sensitivity-and-specificity" id="toc-sensitivity-and-specificity" class="nav-link" data-scroll-target="#sensitivity-and-specificity"><span class="header-section-number">7.6.5</span> Sensitivity and Specificity</a></li>
  </ul></li>
  <li><a href="#receiver-operating-characteristic-curve" id="toc-receiver-operating-characteristic-curve" class="nav-link" data-scroll-target="#receiver-operating-characteristic-curve"><span class="header-section-number">7.7</span> Receiver Operating Characteristic Curve</a>
  <ul class="collapse">
  <li><a href="#separating-s-and--s" id="toc-separating-s-and--s" class="nav-link" data-scroll-target="#separating-s-and--s"><span class="header-section-number">7.7.1</span> Separating +’s and -’s</a></li>
  <li><a href="#roc-curve" id="toc-roc-curve" class="nav-link" data-scroll-target="#roc-curve"><span class="header-section-number">7.7.2</span> ROC Curve</a></li>
  <li><a href="#constructing-roc-curve" id="toc-constructing-roc-curve" class="nav-link" data-scroll-target="#constructing-roc-curve"><span class="header-section-number">7.7.3</span> Constructing ROC Curve</a></li>
  <li><a href="#construct-roc-example" id="toc-construct-roc-example" class="nav-link" data-scroll-target="#construct-roc-example"><span class="header-section-number">7.7.4</span> Construct ROC Example</a></li>
  <li><a href="#auc" id="toc-auc" class="nav-link" data-scroll-target="#auc"><span class="header-section-number">7.7.5</span> AUC</a></li>
  <li><a href="#lr-and-tree-roc-curves" id="toc-lr-and-tree-roc-curves" class="nav-link" data-scroll-target="#lr-and-tree-roc-curves"><span class="header-section-number">7.7.6</span> LR and Tree ROC Curves</a></li>
  </ul></li>
  <li><a href="#ethical-considerations-in-predictive-modeling" id="toc-ethical-considerations-in-predictive-modeling" class="nav-link" data-scroll-target="#ethical-considerations-in-predictive-modeling"><span class="header-section-number">7.8</span> Ethical Considerations in Predictive Modeling</a>
  <ul class="collapse">
  <li><a href="#assumptions-in-predictive-models" id="toc-assumptions-in-predictive-models" class="nav-link" data-scroll-target="#assumptions-in-predictive-models"><span class="header-section-number">7.8.1</span> Assumptions in Predictive Models</a></li>
  <li><a href="#amazon-hiring-algorithm" id="toc-amazon-hiring-algorithm" class="nav-link" data-scroll-target="#amazon-hiring-algorithm"><span class="header-section-number">7.8.2</span> Amazon Hiring Algorithm</a></li>
  <li><a href="#facial-recognition" id="toc-facial-recognition" class="nav-link" data-scroll-target="#facial-recognition"><span class="header-section-number">7.8.3</span> Facial Recognition</a></li>
  <li><a href="#comments" id="toc-comments" class="nav-link" data-scroll-target="#comments"><span class="header-section-number">7.8.4</span> Comments</a></li>
  <li><a href="#modeling-for-prediction-1" id="toc-modeling-for-prediction-1" class="nav-link" data-scroll-target="#modeling-for-prediction-1"><span class="header-section-number">7.8.5</span> Modeling for Prediction</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Predictive Modeling</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="learning-outcomes" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="learning-outcomes">Learning Outcomes</h3>
<p><strong>Conceptual Learning Outcomes</strong><br>
26. Explain how model complexity relates to training and test error, prediction variance and bias, and overfitting.&nbsp;<br>
27. Explain how to use cross-validation in model selection.&nbsp;<br>
28. Explain how complexity parameters associated with ridge regression, decision trees, and splines impact variance, bias, and likelihood of overfitting.&nbsp;<br>
29. Make predictions from a decision tree.&nbsp;<br>
30. Calculate classification accuracy, sensitivity, specificity, confusion matrix, and receiver operating characteristic curves.<br>
31. Assess ethical considerations associated with predictive models in context.</p>
<p><strong>Computational Learning Outcomes</strong><br>
K. Perform cross-validation to build and assess predictive models in R.<br>
L. Make predictions on new data using predictive models in R.</p>
</section>
<section id="modeling-for-prediction" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="modeling-for-prediction"><span class="header-section-number">7.1</span> Modeling for Prediction</h2>
<section id="overview" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">7.1.1</span> Overview</h3>
<p>We’ve previously learned how to build models for the purpose of interpretation, when our primary focus is on understanding relationships between variables in the model. In this chapter, we’ll examine how to build models for situations when we are not interested in understanding relationships between variables, and instead care only about making the most accurate predictions possible.</p>
<p>We’ve seen that when we model for interpretation, we encounter a tradeoff between model complexity and interpretability. We wanted to choose a model that is complex enough to reasonably approximate the structure of the underlying data, but at the same time, not so complicated that it becomes hard to interpret. When modeling for prediction, we don’t need to worry about interpretability, which can sometimes make more complex models more desirable. Nevertheless, we’ll encounter a different kind of tradeoff, involving model complexity, that we’ll have to think about, and we’ll see that more complex models do not always lead to better predictions.</p>
<p><strong>Predictive Modeling Vocabulary</strong></p>
<ul>
<li><p>The new data on which we make predictions are called <strong>test data</strong>.</p></li>
<li><p>The data used to fit the model are called <strong>training data</strong>.</p></li>
</ul>
<p>In the training data, we know the values of the explanatory and response variables. In the test data, we know only the values of the explanatory variables and want to predict the values of the response variable.</p>
</section>
<section id="illustration-of-predictive-modeling" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="illustration-of-predictive-modeling"><span class="header-section-number">7.1.2</span> Illustration of Predictive Modeling</h3>
<p>The illustration shows observations from a simulated dataset consisting of 100 observations of a single explanatory variable <span class="math inline">\(x\)</span>, and response variable <span class="math inline">\(y\)</span>. We want to find a model that captures the trend in the data and will be best able to predict new values of y, for given x.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>We’ll fit several different polynomial models to the data, increasing in complexity from the most simple model we could possibly use, a constant model, to a very complex eighth degree polynomial model.</p>
<p><strong>Constant Model to Sample Data</strong></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="864"></p>
</figure>
</div>
</div>
</div>
<p>The plot below shows models of degree 0, 1, 3, and 7 fit to the training data on the same plot.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>We see that the flexibility of the model increases as we add higher-order terms. The curve is allowed to have more twists and bends. For higher-order, more complex models, individual points have more influence on the shape of the curve. This can be both a good and bad thing, as it allows the model to better bend and fit the data, but also makes it susceptible to the influence of outliers.</p>
</section>
<section id="predicting-new-data" class="level3" data-number="7.1.3">
<h3 data-number="7.1.3" class="anchored" data-anchor-id="predicting-new-data"><span class="header-section-number">7.1.3</span> Predicting New Data</h3>
<p>Now, suppose we have a new dataset of 100 x-values, and want to predict <span class="math inline">\(y\)</span>. The new data are shown below.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>We fit polynomial models of degree 0 through 8 to the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>Sim_M0 <span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span><span class="dv">1</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>Sim_M1 <span class="ot">&lt;-</span><span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>Sim_M2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>Sim_M3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">3</span>))</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>Sim_M4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">3</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">4</span>))</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>Sim_M5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">3</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">4</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">5</span>))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>Sim_M6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">3</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">4</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">5</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">6</span>))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>Sim_M7 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">3</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">4</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">5</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">6</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">7</span>))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>Sim_M8 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Sampdf, y<span class="sc">~</span>x<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">3</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">4</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">5</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">6</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">7</span>)<span class="sc">+</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">8</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We plot models 0, 1, 3, and 7 and see which best fits the data.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>Notice that while there were some high y-values on around x=1 in the training data, which pulled model 7 upward in that region, these values are not present in the new data. Model M7 appears to overpredict most of the y-values in this region. It appears that the behavior in the training data close to <span class="math inline">\(x=1\)</span> was due more to noise than signal, and the more flexible model suffers because it responds too aggressively to the noise.</p>
<p>We predict the values of the new observations, using each of the 9 models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg0Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M0, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg1Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M1, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg2Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M2, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg3Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M3, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg4Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M4, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg5Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M5, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg6Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M6, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg7Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M7, <span class="at">newdata=</span>Newdf)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>Newdf<span class="sc">$</span>Deg8Pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(Sim_M8, <span class="at">newdata=</span>Newdf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In fact, since these data were simulated, we know the true value of <span class="math inline">\(y\)</span>, so we can compare the predicted values to the true ones.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(Newdf <span class="sc">%&gt;%</span> dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(samp)) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">1</span>) <span class="sc">%&gt;%</span> <span class="fu">head</span>(<span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       x    y Deg0Pred Deg1Pred Deg2Pred Deg3Pred Deg4Pred Deg5Pred Deg6Pred
108  5.5  5.5      1.2      1.1      0.4     -0.1     -0.3      0.1      0.4
4371 2.1  3.9      1.2      1.9      2.0      3.7      3.9      4.3      3.8
4839 3.2  1.5      1.2      1.6      1.3      3.2      3.4      2.8      2.2
6907 2.1  6.8      1.2      1.9      2.0      3.7      4.0      4.2      3.8
7334 2.9 -1.0      1.2      1.7      1.4      3.4      3.6      3.1      2.5
     Deg7Pred Deg8Pred
108       0.3      0.3
4371      3.4      3.5
4839      2.2      2.1
6907      3.4      3.5
7334      2.3      2.2</code></pre>
</div>
</div>
</section>
<section id="prediction-error" class="level3" data-number="7.1.4">
<h3 data-number="7.1.4" class="anchored" data-anchor-id="prediction-error"><span class="header-section-number">7.1.4</span> Prediction Error</h3>
<p>For quantitative response variables, we can evaluate the predictions by calculating the average of the squared differences between the true and predicted values. Often, we look at the square root of this quantity. This is called the Root Mean Square Prediction Error (RMSPE).</p>
<p><span class="math display">\[
\text{RMSPE} = \sqrt{\displaystyle\sum_{i=1}^{n'}\frac{(y_i-\hat{y}_i)^2}{n'}},
\]</span></p>
<p>where <span class="math inline">\(n'\)</span> represents the number of new cases being predicted.</p>
<p>We calculate RMSPE for each of the 9 models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>RMSPE0 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg0Pred)<span class="sc">^</span><span class="dv">2</span>)) </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>RMSPE1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg1Pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>RMSPE2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg2Pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>RMSPE3 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg3Pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>RMSPE4 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg4Pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>RMSPE5 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg5Pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>RMSPE6 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg6Pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>RMSPE7 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg7Pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>RMSPE8 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((Newdf<span class="sc">$</span>y<span class="sc">-</span>Newdf<span class="sc">$</span>Deg8Pred)<span class="sc">^</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Prediction error on new data</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Degree</th>
<th style="text-align: right;">RMSPE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">4.05</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3.85</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">3.73</td>
</tr>
<tr class="even">
<td style="text-align: right;">3</td>
<td style="text-align: right;">3.26</td>
</tr>
<tr class="odd">
<td style="text-align: right;">4</td>
<td style="text-align: right;">3.28</td>
</tr>
<tr class="even">
<td style="text-align: right;">5</td>
<td style="text-align: right;">3.34</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6</td>
<td style="text-align: right;">3.35</td>
</tr>
<tr class="even">
<td style="text-align: right;">7</td>
<td style="text-align: right;">3.37</td>
</tr>
<tr class="odd">
<td style="text-align: right;">8</td>
<td style="text-align: right;">3.35</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The third degree model did the best at predicting the new data.</p>
<p>Notice that making the model more complex beyond third degree not only didn’t help, but actually hurt prediction accuracy.</p>
<p>Now, let’s examine the behavior if we had fit the models to the data, instead of the test data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>RMSE0 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M0<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>RMSE1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M1<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>RMSE2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M2<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>RMSE3 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M3<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>RMSE4 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M4<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>RMSE5 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M5<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>RMSE6 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M6<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>RMSE7 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M7<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>RMSE8 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(Sim_M8<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Error on training data</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Degree</th>
<th style="text-align: right;">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">3.43</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3.37</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">3.30</td>
</tr>
<tr class="even">
<td style="text-align: right;">3</td>
<td style="text-align: right;">2.91</td>
</tr>
<tr class="odd">
<td style="text-align: right;">4</td>
<td style="text-align: right;">2.91</td>
</tr>
<tr class="even">
<td style="text-align: right;">5</td>
<td style="text-align: right;">2.84</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6</td>
<td style="text-align: right;">2.81</td>
</tr>
<tr class="even">
<td style="text-align: right;">7</td>
<td style="text-align: right;">2.80</td>
</tr>
<tr class="odd">
<td style="text-align: right;">8</td>
<td style="text-align: right;">2.80</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>Degree <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">8</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>Test_Error <span class="ot">&lt;-</span> <span class="fu">c</span>(RMSPE0, RMSPE1, RMSPE2, RMSPE3, RMSPE4, RMSPE5, RMSPE6, RMSPE7, RMSPE8)<span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">2</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>Train_Error <span class="ot">&lt;-</span> <span class="fu">c</span>(RMSE0, RMSE1, RMSE2, RMSE3, RMSE4, RMSE5, RMSE6, RMSE7, RMSE8) <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">2</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>RMSPEdf <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Degree, Train_Error, Test_Error)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>RMSPEdf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Degree Train_Error Test_Error
1      0        3.43       4.05
2      1        3.37       3.85
3      2        3.30       3.73
4      3        2.91       3.26
5      4        2.91       3.28
6      5        2.84       3.34
7      6        2.81       3.35
8      7        2.80       3.37
9      8        2.80       3.35</code></pre>
</div>
</div>
<p>Notice that the most complex model achieves the best performance on the training data, but not on the test data.</p>
<p>As the model complexity grows, the model will always fit the training data better, but that does not mean it will perform better on new data. It is possible to start modeling noise, rather than true signal in the training data, which hurts the accuracy of the model when applied to new data.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Training error decreases as model becomes more complex<br>
</li>
<li>Testing error is lowest for the 3rd degree model, then starts to increase again</li>
</ul>
<p>Of the models we looked at, the third degree model does the best. The estimates of its coefficients are shown below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>Sim_M3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x + I(x^2) + I(x^3), data = Sampdf)

Coefficients:
(Intercept)            x       I(x^2)       I(x^3)  
   -0.54165      4.16638     -1.20601      0.08419  </code></pre>
</div>
</div>
<p>In fact, the data were generated from the model <span class="math inline">\(y_i = 0 + 4.5x  - 1.4x^2 +  0.1x^3 + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,3)\)</span></p>
<p>The graph below shows the 100 points in our sample in green and the population of points that could have come from this equation in red.</p>
<p>We compare the true expected response curve (in yellow) to the estimated curve in blue. We see that they are not identical, but close.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="variance-bias-tradeoff" class="level3" data-number="7.1.5">
<h3 data-number="7.1.5" class="anchored" data-anchor-id="variance-bias-tradeoff"><span class="header-section-number">7.1.5</span> Variance Bias Tradeoff</h3>
<p>As we make a model more complex (such as by adding more variables or higher order polynomial terms), it will always fit the training data better. However, at some point, it will begin to model random noise, rather than true signal in the training data, and thus will perform worse on new data. This is called <strong>overfitting.</strong></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<div style="page-break-after: always;"></div>
<p>Suppose <span class="math inline">\(Y_i = f(x_i) + \epsilon_i\)</span>, where <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span>.</p>
<p>Let <span class="math inline">\(\hat{f}\)</span> represent the function of our explanatory variable(s) <span class="math inline">\(x^*\)</span> used to predict the value of response variable <span class="math inline">\(y^*\)</span>. Thus <span class="math inline">\(\hat{y}^* = f(x^*)\)</span>.</p>
<p>Prediction error is given by <span class="math inline">\(\left(y^* - \hat{y}\right)^2 = \left(y^* - \hat{f}(x^*)\right)^2\)</span>.</p>
<p>There are three factors that contribute to prediction error RMSPE.</p>
<ol type="1">
<li><p><strong>Model Bias</strong> - Our model might not be complex enough to capture the true relationship between the response and explanatory variable(s). For example, if we use a linear or quadratic model when the true relationship is cubic, our predictions will suffer from model bias. Model bias pertains to the difference between the true response function value <span class="math inline">\(f(x^*)\)</span>, and the expected value of <span class="math inline">\(\hat{f}(x^*)\)</span> that would be obtained in the long run over many samples.</p></li>
<li><p><strong>Model Variance</strong> - Individual observations in the training data are subject to random sampling variability. As model complexity increases, it becomes more flexible and prone to being pulled away from the true relationship because of outliers in the training data.</p></li>
<li><p><strong>Prediction Variance</strong> - Even if two observations have the same value(s) for every explanatory variable, they will usually have different response values, due to random noise (i.e.&nbsp;the <span class="math inline">\(\epsilon_i\sim\mathcal{N}(0,\sigma)\)</span> term). So, even if we really knew the relationship between the response and explanatory variable(s), we would still not get every prediction exactly correct.</p></li>
</ol>
<p>We cannot do anything about prediction variance, but we can try to control model bias and variance through our choice of model. If we could figure out how to minimize bias while also minimizing variance associated with a prediction, that would be great! Unfortunately, this is not possible. As model complexity (flexibility) increases, bias decreases. Variance, however, increases. Thus, we cannot make both of these smallest at the same time. Instead, the goal will be to find a model that is complex enough to keep bias fairly low, while not so complex that variability gets too big.</p>
<p>In fact, it can be shown that:</p>
<p><span class="math inline">\(\text{Expected RMSPE} = \text{Variance} + \text{Bias}^2\)</span></p>
<p>Our goal is the find the “sweetspot” where expected prediction error is minimized.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="cross-validation" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="cross-validation"><span class="header-section-number">7.2</span> Cross-Validation</h2>
<section id="cross-validation-illustration" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="cross-validation-illustration"><span class="header-section-number">7.2.1</span> Cross-Validation Illustration</h3>
<p>We’ve seen that training error is not an accurate approximation of test error. Instead, we’ll approximate test error, by setting aside a set of the training data, and using it as if it were a test set. This process is called <strong>cross-validation</strong>, and the set we put aside is called the <strong>validation set.</strong></p>
<ol type="1">
<li>Partition data into disjoint sets (folds). Approximately 5 folds recommended.<br>
</li>
<li>Build a model using 4 of the 5 folds.<br>
</li>
<li>Use model to predict responses for remaining fold.</li>
<li>Calculate root mean square error <span class="math inline">\(RMSPE=\displaystyle\sqrt{\frac{\sum((\hat{y}_i-y_i)^2)}{n'}}\)</span>.<br>
</li>
<li>Repeat for each of 5 folds.<br>
</li>
<li>Average RMSPE values across folds.</li>
</ol>
<p>If computational resources permit, it is often beneficial to perform CV multiple times, using different sets of folds.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="CV2.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>https://www.researchgate.net/figure/A-schematic-illustration-of-K-fold-cross-validation-for-K-5-Original-dataset-shown_fig5_311668395</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="ames-housing-data" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="ames-housing-data"><span class="header-section-number">7.2.2</span> Ames Housing Data</h3>
<p>We’ll use it to compare five different models for house prices among a dataset of 1,000 houses sold in Ames, IA between 2006 and 2010. We have data on 25 different explanatory variables.</p>
<p>This is actually a subset of a larger dataset available in the <code>Ames Housing</code> R package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#library(AmesHousing)</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">#data("ames_raw")</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>Ames_Train <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"Ames_Train_Data.csv"</span>)  <span class="co"># Load data</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)   <span class="co"># load caret package</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AmesHousing)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"ames_raw"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(ames_raw)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> ames_raw <span class="sc">%&gt;%</span> <span class="fu">mutate_if</span>(is.character,as.factor)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>Ames_Num <span class="ot">&lt;-</span> <span class="fu">select_if</span>(ames_raw, is.numeric)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> ames_raw[<span class="fu">complete.cases</span>(Ames_Num),]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> ames_raw <span class="sc">%&gt;%</span> <span class="fu">mutate_if</span>(is.character, addNA)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> ames_raw <span class="sc">%&gt;%</span> <span class="fu">mutate_if</span>(is.factor, addNA)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>ames_raw<span class="sc">$</span>PID <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(ames_raw<span class="sc">$</span>PID)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> ames_raw <span class="sc">%&gt;%</span> <span class="fu">select</span>( <span class="st">`</span><span class="at">Overall Qual</span><span class="st">`</span>, <span class="st">`</span><span class="at">Year Built</span><span class="st">`</span>, <span class="st">`</span><span class="at">Mas Vnr Area</span><span class="st">`</span>, <span class="st">`</span><span class="at">Central Air</span><span class="st">`</span>, <span class="st">`</span><span class="at">Gr Liv Area</span><span class="st">`</span>, <span class="st">`</span><span class="at">Lot Frontage</span><span class="st">`</span>, <span class="st">`</span><span class="at">1st Flr SF</span><span class="st">`</span>, <span class="st">`</span><span class="at">Bedroom AbvGr</span><span class="st">`</span>, <span class="st">`</span><span class="at">TotRms AbvGrd</span><span class="st">`</span>, <span class="fu">everything</span>())</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> ames_raw <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(Utilities, <span class="st">`</span><span class="at">Exterior 2nd</span><span class="st">`</span>, <span class="st">`</span><span class="at">Bldg Type</span><span class="st">`</span>, <span class="st">`</span><span class="at">Bsmt Cond</span><span class="st">`</span>, <span class="st">`</span><span class="at">BsmtFin Type 1</span><span class="st">`</span>, <span class="st">`</span><span class="at">Low Qual Fin SF</span><span class="st">`</span>, <span class="st">`</span><span class="at">Total Bsmt SF</span><span class="st">`</span>, <span class="st">`</span><span class="at">BsmtFin Type 2</span><span class="st">`</span>, <span class="st">`</span><span class="at">Bsmt Cond</span><span class="st">`</span>, <span class="st">`</span><span class="at">Exterior 1st</span><span class="st">`</span>, <span class="st">`</span><span class="at">House Style</span><span class="st">`</span>))</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>ames_raw <span class="ot">&lt;-</span> ames_raw <span class="sc">|&gt;</span> <span class="fu">mutate_if</span>(is.factor, droplevels)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10302021</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(ames_raw))</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>Ames_Train <span class="ot">&lt;-</span> ames_raw[samp[<span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>],]</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>Ames_Test <span class="ot">&lt;-</span> ames_raw[samp[<span class="dv">1001</span><span class="sc">:</span><span class="dv">2000</span>],]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>Ames_Train <span class="ot">&lt;-</span> Ames_Train <span class="sc">|&gt;</span> <span class="fu">mutate_if</span>(is.factor, droplevels)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>Ames_Test <span class="ot">&lt;-</span> Ames_Test <span class="sc">|&gt;</span> <span class="fu">mutate_if</span>(is.factor, droplevels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Ames_Train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     Overall Qual Year Built Mas Vnr Area Central Air Gr Liv Area Lot Frontage
859             5       1972            0           Y         864           36
1850            7       1997         1600           Y        1950           66
1301            5       1948            0           Y        1122          100
981             5       1972            0           Y         796           50
2694            6       1937            0           Y        1376           50
2209            5       1938            0           Y         954           50
     1st Flr SF Bedroom AbvGr TotRms AbvGrd Order  PID MS SubClass MS Zoning
859         864             3             5   859 2256         020        RL
1850        975             3             7  1850  976         060        FV
1301       1122             2             6  1301 1572         020        RM
981         796             2             4   981 2891         085        RL
2694        780             3             7  2694 1805         050        RM
2209        954             2             5  2209 2561         030        RL
     Lot Area Street Alley Lot Shape Land Contour Lot Config Land Slope
859     15523   Pave  &lt;NA&gt;       IR1          Lvl    CulDSac        Gtl
1850     7399   Pave  Pave       IR1          Lvl     Inside        Gtl
1301    12000   Pave  &lt;NA&gt;       Reg          Lvl     Inside        Gtl
981      7689   Pave  &lt;NA&gt;       IR1          Lvl     Inside        Gtl
2694     8600   Pave  &lt;NA&gt;       Reg          Bnk     Inside        Gtl
2209     6305   Pave  &lt;NA&gt;       Reg          Bnk     Inside        Gtl
     Neighborhood Condition 1 Condition 2 Overall Cond Year Remod/Add
859       CollgCr        Norm        Norm            6           1972
1850      Somerst        Norm        Norm            5           1998
1301      OldTown        Norm        Norm            7           2005
981       Mitchel        Norm        Norm            8           1972
2694       IDOTRR        Norm        Norm            6           1950
2209      Crawfor        Norm        Norm            7           1950
     Roof Style Roof Matl Mas Vnr Type Exter Qual Exter Cond Foundation
859       Gable   CompShg         None         TA         TA     CBlock
1850        Hip   CompShg      BrkFace         Gd         TA      PConc
1301      Gable   CompShg         None         TA         TA     CBlock
981       Gable   CompShg         None         TA         TA     CBlock
2694      Gable   CompShg         None         TA         TA     BrkTil
2209      Gable   CompShg         None         TA         Gd      PConc
     Bsmt Qual Bsmt Exposure BsmtFin SF 1 BsmtFin SF 2 Bsmt Unf SF Heating
859         TA            Av          460            0         404    GasA
1850        Gd            No          649            0         326    GasA
1301        TA            No          144          608         172    GasA
981         Gd            Av          720           76           0    GasA
2694        TA            No            0            0         780    GasA
2209        Fa            No            0            0         920    GasA
     Heating QC Electrical 2nd Flr SF Bsmt Full Bath Bsmt Half Bath Full Bath
859          Ex      SBrkr          0              1              0         1
1850         Ex      SBrkr        975              0              0         2
1301         Ex      SBrkr          0              1              0         1
981          Gd      SBrkr          0              0              1         1
2694         TA      SBrkr        596              0              0         2
2209         Ex      SBrkr          0              0              0         1
     Half Bath Kitchen AbvGr Kitchen Qual Functional Fireplaces Fireplace Qu
859          0             1           TA        Typ          1           Fa
1850         1             1           Gd        Typ          1           TA
1301         0             1           Gd        Typ          0         &lt;NA&gt;
981          0             1           TA        Typ          0         &lt;NA&gt;
2694         0             1           TA        Typ          1           Gd
2209         0             1           Fa        Typ          1           Gd
     Garage Type Garage Yr Blt Garage Finish Garage Cars Garage Area
859       Attchd          1972           Unf           1         338
1850      Detchd          1997           RFn           2         576
1301      Attchd          1948           Unf           2         528
981       Detchd          1998           Unf           1         336
2694      Detchd          1937           Unf           1         198
2209     Basment          1938           Unf           1         240
     Garage Qual Garage Cond Paved Drive Wood Deck SF Open Porch SF
859           TA          TA           Y            0             0
1850          TA          TA           Y            0            10
1301          TA          TA           Y            0            36
981           TA          TA           Y          138             0
2694          TA          TA           N            0             0
2209          Fa          TA           Y            0             0
     Enclosed Porch 3Ssn Porch Screen Porch Pool Area Pool QC Fence
859               0          0            0         0    &lt;NA&gt;  &lt;NA&gt;
1850              0          0          198         0    &lt;NA&gt;  &lt;NA&gt;
1301              0          0            0         0    &lt;NA&gt;  GdWo
981               0          0            0         0    &lt;NA&gt; MnPrv
2694              0          0            0         0    &lt;NA&gt;  &lt;NA&gt;
2209              0          0            0         0    &lt;NA&gt; MnPrv
     Misc Feature Misc Val Mo Sold Yr Sold Sale Type Sale Condition SalePrice
859          &lt;NA&gt;        0       8    2009       WD          Normal    133500
1850         &lt;NA&gt;        0       6    2007       WD          Normal    239000
1301         &lt;NA&gt;        0       5    2008       WD          Normal    147000
981          &lt;NA&gt;        0       7    2009       WD          Normal    131900
2694         &lt;NA&gt;        0       6    2006       WD          Normal    119500
2209         &lt;NA&gt;        0       6    2007       WD          Normal    119750</code></pre>
</div>
</div>
</section>
<section id="cross-validation-with-caret" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="cross-validation-with-caret"><span class="header-section-number">7.2.3</span> Cross-Validation with <code>caret</code></h3>
<p>The <code>train</code> function in the <code>caret</code> R package performs cross validation automatically. <code>number</code> represents the number of folds, and repeats is the number of repetitions.</p>
<p>We’ll consider six different models of increasing complexity.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)  </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># set cross-validation settings - use 10 repeats of 10-fold CV</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">"repeatedcv"</span>, <span class="at">number=</span><span class="dv">10</span>, <span class="at">repeats=</span><span class="dv">10</span>, <span class="at">savePredictions =</span> <span class="st">"all"</span> )</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># define models</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># set same random seed before each model to ensure same partitions are used in CV, making them comparable</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10302023</span>)   </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train, </span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                SalePrice <span class="sc">~</span> <span class="st">`</span><span class="at">Overall Qual</span><span class="st">`</span> ,  </span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">"lm"</span>, <span class="at">trControl=</span>control)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10302023</span>) </span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train, </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>                SalePrice <span class="sc">~</span> <span class="st">`</span><span class="at">Overall Qual</span><span class="st">`</span> <span class="sc">+</span>  <span class="st">`</span><span class="at">Gr Liv Area</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Garage Area</span><span class="st">`</span>,  </span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">"lm"</span>, <span class="at">trControl=</span>control)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10302023</span>) </span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>model3 <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train, SalePrice <span class="sc">~</span> <span class="st">`</span><span class="at">Overall Qual</span><span class="st">`</span> <span class="sc">+</span> </span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>                  <span class="st">`</span><span class="at">Gr Liv Area</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Garage Area</span><span class="st">`</span> <span class="sc">+</span> </span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>                  <span class="st">`</span><span class="at">Neighborhood</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Year Built</span><span class="st">`</span>,  </span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">"lm"</span>, <span class="at">trControl=</span>control)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10302023</span>) </span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>model4 <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train, SalePrice <span class="sc">~</span> <span class="st">`</span><span class="at">Overall Qual</span><span class="st">`</span> </span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>                <span class="sc">+</span> <span class="st">`</span><span class="at">Gr Liv Area</span><span class="st">`</span>  <span class="sc">+</span> <span class="st">`</span><span class="at">Garage Area</span><span class="st">`</span> </span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>                <span class="sc">+</span> <span class="st">`</span><span class="at">Neighborhood</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Year Built</span><span class="st">`</span> </span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>                <span class="sc">+</span> <span class="st">`</span><span class="at">Lot Shape</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Land Contour</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Land Slope</span><span class="st">`</span>,</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">"lm"</span>, <span class="at">trControl=</span>control)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10302023</span>) </span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>model5 <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train, SalePrice <span class="sc">~</span> <span class="st">`</span><span class="at">Overall Qual</span><span class="st">`</span> </span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>                <span class="sc">+</span> <span class="st">`</span><span class="at">Gr Liv Area</span><span class="st">`</span>  <span class="sc">+</span> <span class="st">`</span><span class="at">Garage Area</span><span class="st">`</span> </span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>                <span class="sc">+</span> <span class="st">`</span><span class="at">Neighborhood</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Year Built</span><span class="st">`</span> </span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>                 <span class="sc">+</span> <span class="st">`</span><span class="at">Lot Shape</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Land Contour</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">Land Slope</span><span class="st">`</span> <span class="sc">+</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>                 <span class="sc">+</span> <span class="st">`</span><span class="at">Order</span><span class="st">`</span> <span class="sc">+</span> <span class="st">`</span><span class="at">PID</span><span class="st">`</span> ,</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>                <span class="at">method=</span><span class="st">"lm"</span>, <span class="at">trControl=</span>control)</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10302023</span>) </span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>model6 <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train, SalePrice <span class="sc">~</span> .,  <span class="at">method=</span><span class="st">"lm"</span>, <span class="at">trControl=</span>control)  <span class="co"># include everything linearly</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Cross validation root mean square error is shown below. This is an estimate of the root mean square prediction error we would see when making predictions on new data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate RMSPE for each model</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>CVRMSE1 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((model1<span class="sc">$</span>pred<span class="sc">$</span>obs<span class="sc">-</span>model1<span class="sc">$</span>pred<span class="sc">$</span>pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>CVRMSE2 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((model2<span class="sc">$</span>pred<span class="sc">$</span>obs<span class="sc">-</span>model2<span class="sc">$</span>pred<span class="sc">$</span>pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>CVRMSE3 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((model3<span class="sc">$</span>pred<span class="sc">$</span>obs<span class="sc">-</span>model3<span class="sc">$</span>pred<span class="sc">$</span>pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>CVRMSE4 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((model4<span class="sc">$</span>pred<span class="sc">$</span>obs<span class="sc">-</span>model4<span class="sc">$</span>pred<span class="sc">$</span>pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>CVRMSE5 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((model5<span class="sc">$</span>pred<span class="sc">$</span>obs<span class="sc">-</span>model5<span class="sc">$</span>pred<span class="sc">$</span>pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>CVRMSE6 <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((model6<span class="sc">$</span>pred<span class="sc">$</span>obs<span class="sc">-</span>model6<span class="sc">$</span>pred<span class="sc">$</span>pred)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>CVRMSE1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 49605.77</code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>CVRMSE2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 43333.4</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>CVRMSE3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 39057.19</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>CVRMSE4</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 39287.21</code></pre>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>CVRMSE5</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 39340.58</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>CVRMSE6</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 53849.8</code></pre>
</div>
</div>
<p>We see that in this case, Model 3 performed the best on the validation data. Adding variables like lot shape, land contour, and land slope did not help with predictions, and actually cause the model to overfit and perform worse. We should use Model 3 to make predictions on new data over the other models seen here. It is likely that there are better models out there than Model 3, likely with complexity somewhere between that of Model 3 and Models 5-6. Perhaps you can find one.</p>
<p>Once we have our preferred model, we can read in our test data and make predictions, and display the first 10 predicted values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>Ames_Test <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"Ames_Test_Data.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The first ten rows of the test data are shown below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Ames_Test, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 25
     PID `MS SubClass` `Lot Frontage` `Lot Area` `Lot Shape` `Land Contour`
   &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;         
 1  1659            30             90       8100 Reg         Lvl           
 2   677            20             49      15256 IR1         Lvl           
 3  1976            20             82      20270 IR1         Lvl           
 4    42            60             50      13128 IR1         HLS           
 5  1442            20             60       7200 Reg         Lvl           
 6  1782            70             57       8094 Reg         Lvl           
 7  2389            85             75       9825 Reg         Low           
 8  1657            70             60      11340 Reg         Lvl           
 9   401            60             82       9709 IR1         Lvl           
10  2571            50             66      21780 Reg         Lvl           
# ℹ 19 more variables: Neighborhood &lt;chr&gt;, `Bldg Type` &lt;chr&gt;,
#   `Overall Qual` &lt;dbl&gt;, `Overall Cond` &lt;dbl&gt;, `Year Built` &lt;dbl&gt;,
#   `Year Remod/Add` &lt;dbl&gt;, `Total Bsmt SF` &lt;dbl&gt;, `Central Air` &lt;chr&gt;,
#   `1st Flr SF` &lt;dbl&gt;, `2nd Flr SF` &lt;dbl&gt;, `Gr Liv Area` &lt;dbl&gt;,
#   `Full Bath` &lt;dbl&gt;, `TotRms AbvGrd` &lt;dbl&gt;, Fireplaces &lt;dbl&gt;,
#   `Garage Cars` &lt;dbl&gt;, `Garage Area` &lt;dbl&gt;, `Mo Sold` &lt;dbl&gt;, `Yr Sold` &lt;dbl&gt;,
#   SalePrice &lt;lgl&gt;</code></pre>
</div>
</div>
<p>We use Model 3 to predict the prices of the new houses. The first 10 predictions are shown below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model3, <span class="at">newdata=</span>Ames_Test)  <span class="co"># substitute your best model</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">data.frame</span>(predictions), <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   predictions
1    155806.18
2    245394.28
3    238933.54
4    243591.93
5    115427.13
6    162572.07
7    106909.10
8     47830.52
9    331618.06
10   179100.12</code></pre>
</div>
</div>
<p>A quick look at the data reveals that the one predicted to be most expensive was House #9, which was a newer house built in 2007, and was the biggest and one of the highest overall quality houses among the 10.</p>
<p>We create a csv file containing the predictions, using the code below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span>(predictions, <span class="at">file =</span> <span class="st">"predictions.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="ridge-regression" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="ridge-regression"><span class="header-section-number">7.3</span> Ridge Regression</h2>
<section id="complexity-in-model-coefficients" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="complexity-in-model-coefficients"><span class="header-section-number">7.3.1</span> Complexity in Model Coefficients</h3>
<p>We’ve thought about complexity in terms of the number of terms we include in a model, as well as whether we include quadratic terms and higher order terms and interactions. We can also think about model complexity in terms of the coefficients <span class="math inline">\(b_1, \ldots, b_p\)</span>. Larger values of <span class="math inline">\(b_1, \ldots, b_p\)</span> are associated with more complex models. Smaller values of <span class="math inline">\(b_1, \ldots, b_p\)</span> are associated with less complex models. When <span class="math inline">\(b_j=0\)</span>, this mean variable <span class="math inline">\(j\)</span> is not used in the model.</p>
<p>To illustrate, we fit a regression model to the Ames housing dataset, which includes 24 possible explanatory variables, in addition to price.</p>
<p>We’ll begin by standardizing all variables in the dataset using the <code>scale</code> command. This involves subtracting the mean and dividing by the standard deviation. Standardizing ensures that all variables are on the same scale. If we didn’t do this, then the weight given to each variable might differ depending on its units of measure.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>Ames_Train_sc <span class="ot">&lt;-</span> Ames_Train <span class="sc">|&gt;</span>  <span class="fu">mutate_if</span>(is.numeric, scale) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The full list of coefficient estimates is shown below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>M_OLS <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Ames_Train_sc, SalePrice <span class="sc">~</span> .)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>M_OLS<span class="sc">$</span>coefficients</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            (Intercept)          `Overall Qual`            `Year Built` 
        -13.59130882125           0.12172875370           0.18710242157 
         `Mas Vnr Area`          `Central Air`Y           `Gr Liv Area` 
          0.08021260696          -0.04619169355           0.23762329102 
         `Lot Frontage`            `1st Flr SF`         `Bedroom AbvGr` 
         -0.00429094489           0.06991064978          -0.02245793663 
        `TotRms AbvGrd`                   Order                     PID 
          0.01757415312           0.09500860850           0.00814856877 
       `MS SubClass`030        `MS SubClass`040        `MS SubClass`045 
          0.02155059515           0.07236147708           0.08858457552 
       `MS SubClass`050        `MS SubClass`060        `MS SubClass`070 
         -0.01640305733          -0.09127505556          -0.01176201580 
       `MS SubClass`075        `MS SubClass`080        `MS SubClass`085 
         -0.13055431025          -0.08036368019          -0.08050060537 
       `MS SubClass`090        `MS SubClass`120        `MS SubClass`160 
         -0.26998526617          -0.25031708359          -0.42965417371 
       `MS SubClass`180        `MS SubClass`190      `MS Zoning`C (all) 
         -0.23213470433          -0.15319391551          -0.47834524646 
          `MS Zoning`FV      `MS Zoning`I (all)           `MS Zoning`RH 
         -0.28507463985          -0.21229264775          -0.16410610735 
          `MS Zoning`RL           `MS Zoning`RM              `Lot Area` 
         -0.21759850136          -0.30565512401           0.07285454709 
             StreetPave               AlleyPave                 AlleyNA 
          0.45956145163           0.03116785010           0.00035798897 
         `Lot Shape`IR2          `Lot Shape`IR3          `Lot Shape`Reg 
          0.10576302368           0.12823643814           0.03300652196 
      `Land Contour`HLS       `Land Contour`Low       `Land Contour`Lvl 
          0.13958728988          -0.27690361930           0.15084179216 
    `Lot Config`CulDSac         `Lot Config`FR2         `Lot Config`FR3 
          0.12860460385          -0.15191268632          -0.17953546763 
     `Lot Config`Inside         `Land Slope`Mod         `Land Slope`Sev 
         -0.01440783225           0.13011816970          -0.29862915223 
    NeighborhoodBlueste      NeighborhoodBrDale     NeighborhoodBrkSide 
          0.23434173527           0.25354320980           0.17654221032 
    NeighborhoodClearCr     NeighborhoodCollgCr     NeighborhoodCrawfor 
          0.09100974262          -0.00057509876           0.35488850236 
    NeighborhoodEdwards     NeighborhoodGilbert      NeighborhoodGreens 
         -0.09239036865           0.02406940481           0.05756764076 
     NeighborhoodIDOTRR     NeighborhoodMeadowV     NeighborhoodMitchel 
          0.15383179212           0.23298493233          -0.11438052494 
      NeighborhoodNAmes     NeighborhoodNoRidge     NeighborhoodNPkVill 
          0.02197635792           0.39600745608           0.24174493098 
    NeighborhoodNridgHt      NeighborhoodNWAmes     NeighborhoodOldTown 
          0.42434522209          -0.04153578370           0.12156771029 
     NeighborhoodSawyer     NeighborhoodSawyerW     NeighborhoodSomerst 
          0.08339168198           0.04866431880           0.25224969818 
    NeighborhoodStoneBr       NeighborhoodSWISU      NeighborhoodTimber 
          0.54951171242           0.10506427869           0.01795586846 
    NeighborhoodVeenker      `Condition 1`Feedr       `Condition 1`Norm 
          0.07103275546          -0.00389153252           0.12384803301 
      `Condition 1`PosA       `Condition 1`PosN       `Condition 1`RRAe 
          0.61047137485           0.19577375822          -0.14305492898 
      `Condition 1`RRAn       `Condition 1`RRNn      `Condition 2`Feedr 
          0.09735755018           0.07455474531           0.09422184185 
      `Condition 2`Norm       `Condition 2`PosA       `Condition 2`PosN 
          0.08392208658           0.01845182052          -2.77118265740 
      `Condition 2`RRNn          `Overall Cond`        `Year Remod/Add` 
          0.25685094522           0.07395388864           0.03009699255 
      `Roof Style`Gable     `Roof Style`Gambrel         `Roof Style`Hip 
         -0.01212949831          -0.04656300430          -0.01259174339 
    `Roof Style`Mansard        `Roof Style`Shed      `Roof Matl`CompShg 
          0.23077338051          -0.11780553549           8.27597326004 
     `Roof Matl`Membran      `Roof Matl`Tar&amp;Grv      `Roof Matl`WdShngl 
          9.10486598342           8.05640391369           9.34788521212 
  `Mas Vnr Type`BrkFace      `Mas Vnr Type`None     `Mas Vnr Type`Stone 
         -0.17632717617          -0.06386385349          -0.14509043700 
         `Exter Qual`Fa          `Exter Qual`Gd          `Exter Qual`TA 
         -0.27013813954          -0.46168757537          -0.49820871424 
         `Exter Cond`Fa          `Exter Cond`Gd          `Exter Cond`Po 
         -0.03082238434           0.11871185662          -0.11211143073 
         `Exter Cond`TA        FoundationCBlock         FoundationPConc 
          0.13537361237           0.02635149973           0.05354235814 
         FoundationSlab         FoundationStone          FoundationWood 
         -0.09880253750           0.06424781234          -0.26515863060 
          `Bsmt Qual`Fa           `Bsmt Qual`Gd           `Bsmt Qual`Po 
         -0.23578437965          -0.16449941673           0.72119653468 
          `Bsmt Qual`TA           `Bsmt Qual`NA       `Bsmt Exposure`Gd 
         -0.18381997798           0.36058921359           0.10416303942 
      `Bsmt Exposure`Mn       `Bsmt Exposure`No       `Bsmt Exposure`NA 
         -0.06951087282          -0.07062963631          -0.34886062368 
         `BsmtFin SF 1`          `BsmtFin SF 2`           `Bsmt Unf SF` 
          0.20674038443           0.04997252798           0.07271883848 
            HeatingGasW             HeatingWall          `Heating QC`Fa 
          0.04383900333           0.20322162437          -0.08974832333 
         `Heating QC`Gd          `Heating QC`Po          `Heating QC`TA 
         -0.00937967426          -0.22178284792          -0.07042513045 
        ElectricalFuseF         ElectricalFuseP           ElectricalMix 
          0.00898381678           0.31259189683           0.63780393390 
        ElectricalSBrkr            `2nd Flr SF`        `Bsmt Full Bath` 
         -0.03542484148           0.06406031762          -0.00322398443 
       `Bsmt Half Bath`             `Full Bath`             `Half Bath` 
          0.00838482813           0.02519505108           0.02015786337 
        `Kitchen AbvGr`        `Kitchen Qual`Fa        `Kitchen Qual`Gd 
         -0.03349189241          -0.09607308952          -0.16716388306 
       `Kitchen Qual`TA          FunctionalMaj2          FunctionalMin1 
         -0.16401133535          -0.30302784752          -0.10685732156 
         FunctionalMin2           FunctionalMod           FunctionalTyp 
         -0.15674128599          -0.17753056314           0.05187402523 
             Fireplaces        `Fireplace Qu`Fa        `Fireplace Qu`Gd 
          0.09346633107          -0.15744505091          -0.17518128333 
       `Fireplace Qu`Po        `Fireplace Qu`TA        `Fireplace Qu`NA 
         -0.28539807056          -0.21810062721          -0.06851015534 
    `Garage Type`Attchd    `Garage Type`Basment    `Garage Type`BuiltIn 
         -0.01354841109          -0.00861375121          -0.05669345934 
   `Garage Type`CarPort     `Garage Type`Detchd         `Garage Yr Blt` 
         -0.12923248607          -0.00171401502          -0.01955800208 
     `Garage Finish`RFn      `Garage Finish`Unf           `Garage Cars` 
         -0.05356568330          -0.01828384382           0.02471914400 
          `Garage Area`         `Garage Qual`Fa         `Garage Qual`Gd 
          0.06042408704          -0.86850349015          -0.63039690210 
        `Garage Qual`Po         `Garage Qual`TA         `Garage Cond`Fa 
         -1.65328010914          -0.83578836183           0.91247325140 
        `Garage Cond`Gd         `Garage Cond`Po         `Garage Cond`TA 
          0.79060216838           1.39008604944           0.87884284151 
         `Paved Drive`P          `Paved Drive`Y          `Wood Deck SF` 
          0.06483515908           0.02561801326           0.01158689081 
        `Open Porch SF`        `Enclosed Porch`            `3Ssn Porch` 
         -0.01299180889          -0.00928427635           0.00590680860 
         `Screen Porch`             `Pool Area`             `Pool QC`TA 
          0.02956291048          -0.04923465233           0.30278881156 
            `Pool QC`NA               FenceGdWo              FenceMnPrv 
         -1.24145842019           0.00004591047           0.01932880459 
              FenceMnWw                 FenceNA      `Misc Feature`Gar2 
         -0.01085804835           0.01599859694           6.72349662646 
     `Misc Feature`Othr      `Misc Feature`Shed        `Misc Feature`NA 
          7.02488714846           6.80128988914           6.75717447918 
             `Misc Val`               `Mo Sold`               `Yr Sold` 
          0.01467591793          -0.00862316912           0.09610313650 
         `Sale Type`Con        `Sale Type`ConLD        `Sale Type`ConLI 
          0.09849131799           0.29564887816           0.11747454409 
       `Sale Type`ConLw          `Sale Type`CWD          `Sale Type`New 
          0.13635880661          -0.11779397614           0.28511673010 
         `Sale Type`Oth          `Sale Type`VWD          `Sale Type`WD  
          0.49002891445          -0.14466277644           0.05944448834 
`Sale Condition`AdjLand  `Sale Condition`Alloca  `Sale Condition`Family 
          0.50907010355           0.30168612306           0.00499302864 
 `Sale Condition`Normal `Sale Condition`Partial 
          0.01963743062          -0.05724696756 </code></pre>
</div>
</div>
<p>Let’s focus on the first 10 rows.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">coef</span>(M_OLS),<span class="dv">10</span>) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    (Intercept)  `Overall Qual`    `Year Built`  `Mas Vnr Area`  `Central Air`Y 
        -13.591           0.122           0.187           0.080          -0.046 
  `Gr Liv Area`  `Lot Frontage`    `1st Flr SF` `Bedroom AbvGr` `TotRms AbvGrd` 
          0.238          -0.004           0.070          -0.022           0.018 </code></pre>
</div>
</div>
<p>If all coefficients in the model were 0, then we would be using the most simple constant model, and the prediction for the price of each house would be exactly the same as the overall mean. As <span class="math inline">\(b_j's\)</span> get farther from 0, predictions begin move away from the overall mean and depend more and more on the values or categories of the explanatory variable(s) associated with individual houses. This creates a risk, however, of overfitting.</p>
<p>A way to combat this, other than dropping variables from the model, is to shrink some or all of the regression coefficients closer to 0, pushing predictions closer to the overall mean.</p>
<p>A statistical technique for doing this is called <strong>ridge regression.</strong></p>
</section>
<section id="ridge-regression-penalty" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="ridge-regression-penalty"><span class="header-section-number">7.3.2</span> Ridge Regression Penalty</h3>
<p>We’ve seen that in ordinary least-squares regression, <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span> are chosen in a way that to minimizes</p>
<p><span class="math display">\[
\displaystyle\sum_{i=1}^n (y_i -\hat{y}i)^2 =\displaystyle\sum_{i=1}^{n} (y_i -(b_0 + b_1x{i1} + b_2{x_i2} + \ldots +b_px\_{ip}))^2
\]</span></p>
<p>When <span class="math inline">\(p\)</span> is large and we want to be careful of overfitting, a common approach is to add a “penalty term” to this function, to incentive choosing values of <span class="math inline">\(b_1, \ldots, b_p\)</span> that are closer to 0, thereby “shrinking” the predictions toward the overall mean house price.</p>
<p>Specifically, we minimize:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2  + \lambda\displaystyle\sum_{j=1}^pb_j^2\\ =  &amp; \displaystyle\sum_{i=1}^n (y_i -(b_0 + b_1x_{i1} + b_2x_{i2} + \ldots + b_px_{ip}))^2 + \lambda\displaystyle\sum_{j=1}^pb_j^2
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\lambda\)</span> is a pre-determined positive constant.</p>
<p>Larger values of <span class="math inline">\(b_j\)</span> typically help the model better fit the training data, thereby making the first term smaller, but also make the second term larger. The idea is the find optimal values of <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span> that are large enough to allow the model to fit the data well, thus keeping the first term (SSR) small, while also keeping the penalty term small as well.</p>
</section>
<section id="choosing-lambda" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="choosing-lambda"><span class="header-section-number">7.3.3</span> Choosing <span class="math inline">\(\lambda\)</span></h3>
<p>The value of <span class="math inline">\(\lambda\)</span> is predetermined by the user. The larger the value of <span class="math inline">\(\lambda\)</span>, the more heavily large <span class="math inline">\(b_j's\)</span> are penalized. A value of <span class="math inline">\(\lambda=0\)</span> corresponds to ordinary least-squares.</p>
<p><span class="math display">\[
\begin{aligned}
Q=&amp; \displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2  + \lambda\displaystyle\sum_{j=1}^pb_j^2\\ =  &amp; \displaystyle\sum_{i=1}^n (y_i -(b_0 + b_1x_{i1} + b_2x_{i2} + \ldots + b_px_{ip}))^2 + \lambda\displaystyle\sum_{j=1}^pb_j^2
\end{aligned}
\]</span></p>
<ul>
<li>Small values of <span class="math inline">\(\lambda\)</span> lead to more complex models, with larger <span class="math inline">\(|b_j|\)</span>’s.<br>
</li>
<li>As <span class="math inline">\(\lambda\)</span> increases, <span class="math inline">\(|b_j|\)</span>’s shrink toward 0. The model becomes less complex, thus bias increases, but variance decreases.<br>
</li>
<li>We can use cross validation to determine the optimal value of <span class="math inline">\(\lambda\)</span></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p>When using ridge regression, it is important to standardize each explanatory variable (i.e.&nbsp;subtract the mean and divide by the standard deviation). This ensures each variable has mean 0 and standard deviation 1. Without standardizing the optimal choice of <span class="math inline">\(b_j\)</span>’s would depend on scale, with variables with larger absolute measurements having more influence. We’ll standardize the response variable too. Though this is not strictly necessary, it doesn’t hurt. We can always transform back if necessary.</p>
</section>
<section id="ridge-regression-on-housing-dataset" class="level3" data-number="7.3.4">
<h3 data-number="7.3.4" class="anchored" data-anchor-id="ridge-regression-on-housing-dataset"><span class="header-section-number">7.3.4</span> Ridge Regression on Housing Dataset</h3>
<p>We’ll use the <code>caret</code> package to perform cross validation in order to find the optimal value of <span class="math inline">\(\lambda\)</span>. To use ridge regression, we specify <code>method = "glmnet"</code>, and <code>tuneGrid=expand.grid(alpha=0, lambda=l_vals)</code>. Note the <code>alpha</code> value can be changed to use other types of penalized regression sometimes used in predictive modeling, such as lasso or elastic net.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>control <span class="ot">=</span> <span class="fu">trainControl</span>(<span class="st">"repeatedcv"</span>, <span class="at">number =</span> <span class="dv">10</span>, <span class="at">repeats=</span><span class="dv">10</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>l_vals <span class="ot">=</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="at">length =</span> <span class="dv">1000</span>)  <span class="co"># test values between 1/10000 and 10000</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11162020</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>Housing_ridge <span class="ot">&lt;-</span> <span class="fu">train</span>(SalePrice <span class="sc">~</span> .,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> Ames_Train_sc, <span class="at">method =</span> <span class="st">"glmnet"</span>, <span class="at">trControl=</span>control , </span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">tuneGrid=</span><span class="fu">expand.grid</span>(<span class="at">alpha=</span><span class="dv">0</span>, <span class="at">lambda=</span>l_vals))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Value of <span class="math inline">\(\lambda\)</span> minimizing RMSPE:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>Housing_ridge<span class="sc">$</span>bestTune<span class="sc">$</span>lambda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6248788</code></pre>
</div>
</div>
<p>We examine RMSPE on the withheld data as a function of <span class="math inline">\(\lambda\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-41-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Using <span class="math inline">\(\lambda\)</span> = 0.6248788, obtain the following set of ridge regression coefficients. Notice how the ridge coefficients are typically closer to 0 than the ordinary least squares coefficients, indicating a less complex model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>M_OLS_sc <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">data=</span>Ames_Train_sc, SalePrice <span class="sc">~</span> .)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>OLS_coef <span class="ot">&lt;-</span> M_OLS_sc<span class="sc">$</span>coefficients </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>Ridge_coef <span class="ot">&lt;-</span> <span class="fu">coef</span>(Housing_ridge<span class="sc">$</span>finalModel, Housing_ridge<span class="sc">$</span>bestTune<span class="sc">$</span>lambda)[,<span class="dv">1</span>]</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(OLS_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">3</span>), Ridge_coef[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">3</span>))</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(df) <span class="ot">&lt;-</span><span class="fu">c</span>(<span class="st">"OLS Coeff"</span>, <span class="st">"Ridge Coeff"</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(df[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">OLS Coeff</th>
<th style="text-align: right;">Ridge Coeff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>Overall Qual</code></td>
<td style="text-align: right;">0.122</td>
<td style="text-align: right;">0.104</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Year Built</code></td>
<td style="text-align: right;">0.187</td>
<td style="text-align: right;">0.035</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Mas Vnr Area</code></td>
<td style="text-align: right;">0.080</td>
<td style="text-align: right;">0.062</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Central Air</code>Y</td>
<td style="text-align: right;">-0.046</td>
<td style="text-align: right;">0.041</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Gr Liv Area</code></td>
<td style="text-align: right;">0.238</td>
<td style="text-align: right;">0.078</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Lot Frontage</code></td>
<td style="text-align: right;">-0.004</td>
<td style="text-align: right;">0.009</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>1st Flr SF</code></td>
<td style="text-align: right;">0.070</td>
<td style="text-align: right;">0.071</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Bedroom AbvGr</code></td>
<td style="text-align: right;">-0.022</td>
<td style="text-align: right;">0.014</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>TotRms AbvGrd</code></td>
<td style="text-align: right;">0.018</td>
<td style="text-align: right;">0.050</td>
</tr>
<tr class="even">
<td style="text-align: left;">Order</td>
<td style="text-align: right;">0.095</td>
<td style="text-align: right;">-0.004</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Predictions and residuals for the first six houses in the traning data, using ordinary least squares and ridge regression, are shown below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>MAT <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(SalePrice<span class="sc">~</span>., <span class="at">data=</span>Ames_Train_sc)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>ridge_mod <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">x=</span>MAT, <span class="at">y=</span>Ames_Train_sc<span class="sc">$</span>SalePrice, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda=</span>Housing_ridge<span class="sc">$</span>bestTune<span class="sc">$</span>lambda )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Ames_Train_sc<span class="sc">$</span>SalePrice</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>Pred_OLS <span class="ot">&lt;-</span> <span class="fu">predict</span>(M_OLS_sc)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>Pred_Ridge <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge_mod, <span class="at">newx=</span>MAT)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>OLS_Resid <span class="ot">&lt;-</span> y <span class="sc">-</span> Pred_OLS</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>Ridge_Resid <span class="ot">&lt;-</span> y <span class="sc">-</span> Pred_Ridge</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>Resdf <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, Pred_OLS, Pred_Ridge, OLS_Resid, Ridge_Resid) <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">2</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Resdf) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"y"</span>, <span class="st">"OLS Pred"</span>, <span class="st">"Ridge Pred"</span>, <span class="st">"OLS Resid"</span>, <span class="st">"Ridge Resid"</span>)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(<span class="fu">head</span>(Resdf))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">y</th>
<th style="text-align: right;">OLS Pred</th>
<th style="text-align: right;">Ridge Pred</th>
<th style="text-align: right;">OLS Resid</th>
<th style="text-align: right;">Ridge Resid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">859</td>
<td style="text-align: right;">-0.62</td>
<td style="text-align: right;">-0.46</td>
<td style="text-align: right;">-0.46</td>
<td style="text-align: right;">-0.16</td>
<td style="text-align: right;">-0.16</td>
</tr>
<tr class="even">
<td style="text-align: left;">1850</td>
<td style="text-align: right;">0.68</td>
<td style="text-align: right;">1.19</td>
<td style="text-align: right;">1.05</td>
<td style="text-align: right;">-0.51</td>
<td style="text-align: right;">-0.37</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1301</td>
<td style="text-align: right;">-0.45</td>
<td style="text-align: right;">-0.45</td>
<td style="text-align: right;">-0.50</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">0.04</td>
</tr>
<tr class="even">
<td style="text-align: left;">981</td>
<td style="text-align: right;">-0.64</td>
<td style="text-align: right;">-0.66</td>
<td style="text-align: right;">-0.78</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: right;">0.14</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2694</td>
<td style="text-align: right;">-0.79</td>
<td style="text-align: right;">-0.87</td>
<td style="text-align: right;">-0.75</td>
<td style="text-align: right;">0.07</td>
<td style="text-align: right;">-0.04</td>
</tr>
<tr class="even">
<td style="text-align: left;">2209</td>
<td style="text-align: right;">-0.79</td>
<td style="text-align: right;">-0.70</td>
<td style="text-align: right;">-0.64</td>
<td style="text-align: right;">-0.10</td>
<td style="text-align: right;">-0.15</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="ridge-vs-ols" class="level3" data-number="7.3.5">
<h3 data-number="7.3.5" class="anchored" data-anchor-id="ridge-vs-ols"><span class="header-section-number">7.3.5</span> Ridge vs OLS</h3>
<p>In OLS, we choose <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span> are chosen in a way that minimizes</p>
<p><span class="math display">\[
\displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2 =\displaystyle\sum_{i=1}^n (y_i -(b_0 + b_1x_{i1} + b_2x_{i2} + \ldots + b_px_{ip}))^2
\]</span></p>
<p>OLS: <span class="math inline">\(\displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((y<span class="sc">-</span>Pred_OLS)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 56.94383</code></pre>
</div>
</div>
<p>Ridge: <span class="math inline">\(\displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((y<span class="sc">-</span>Pred_Ridge)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 129.0514</code></pre>
</div>
</div>
<p>Not surprisingly the OLS model achieves smaller <span class="math inline">\(\displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2\)</span>. This has to be true, since the OLS coefficients are chosen to minimize this quantity.</p>
<p>In ridge regression, <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span> are chosen in a way that minimizes</p>
<p><span class="math display">\[
\begin{aligned}
Q=&amp; \displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2  + \lambda\displaystyle\sum_{j=1}^pb_j^2\\ =  &amp; \displaystyle\sum_{i=1}^n (y_i -(b_0 + b_1x_{i1} + b_2x_{i2} + \ldots + b_px_{ip}))^2 + \lambda\displaystyle\sum_{j=1}^pb_j^2
\end{aligned}
\]</span></p>
<p>OLS: <span class="math inline">\(\displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2  + \lambda\displaystyle\sum_{j=1}^pb_j^2\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((y<span class="sc">-</span>Pred_OLS)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> Housing_ridge<span class="sc">$</span>bestTune<span class="sc">$</span>lambda<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">coef</span>(M_OLS_sc)[<span class="sc">-</span><span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 378.9323</code></pre>
</div>
</div>
<p>Ridge: <span class="math inline">\(\displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2  + \lambda\displaystyle\sum_{j=1}^pb_j^2\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((y<span class="sc">-</span>Pred_Ridge)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> Housing_ridge<span class="sc">$</span>bestTune<span class="sc">$</span>lambda<span class="sc">*</span><span class="fu">sum</span>((Ridge_coef)[<span class="sc">-</span><span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 132.3112</code></pre>
</div>
</div>
<p>We see that the ridge coefficients achieve a lower value of Q than the OLS ones.</p>
</section>
<section id="lasso-and-elastic-net" class="level3" data-number="7.3.6">
<h3 data-number="7.3.6" class="anchored" data-anchor-id="lasso-and-elastic-net"><span class="header-section-number">7.3.6</span> Lasso and Elastic Net</h3>
<p>Two other techniques that are similar to ridge regression are lasso and elastic net. Both also aim to avoid overfitting by shrinking regression coefficients toward 0 in a manner similar to ridge regression.</p>
<p>Lasso regression is very similar to ridge regression. Coefficients <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span> are chosen in a way that to minimizes</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2  + \lambda\displaystyle\sum_{j=1}^p|b_j|\\ =  &amp; \displaystyle\sum_{i=1}^n (y_i -(b_0 + b_1x_{i1} + b_2x_{i2} + \ldots + b_px_{ip}))^2 + \lambda\displaystyle\sum_{j=1}^p|b_j|
\end{aligned}
\]</span></p>
<p>Regression with an elastic net uses both ridge and lasso penalty terms and determines the values of <span class="math inline">\(b_0, b_1, \ldots, b_p\)</span> by minimizing</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \displaystyle\sum_{i=1}^n (y_i -\hat{y}_i)^2  + \lambda\displaystyle\sum_{j=1}^p|b_j|\\ =  &amp; \displaystyle\sum_{i=1}^n (y_i -(b_0 + b_1x_{i1} + b_2x_{i2} + \ldots + b_px_{ip}))^2 + \lambda_1\displaystyle\sum_{j=1}^pb_j^2+ \lambda_2\displaystyle\sum_{j=1}^p|b_j|
\end{aligned}
\]</span></p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="decision-trees" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="decision-trees"><span class="header-section-number">7.4</span> Decision Trees</h2>
<section id="basics-of-decision-trees" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="basics-of-decision-trees"><span class="header-section-number">7.4.1</span> Basics of Decision Trees</h3>
<p>A decision tree is a flexible alternative to a regression model. It is said to be <strong>nonparametric</strong> because it does not involve parameters like <span class="math inline">\(\beta_0, \beta_1, \ldots \beta_p\)</span>. A tree makes no assumption about the nature of the relationship between the response and explanatory variables, and instead allows us to learn this relationship from the data. A tree makes prediction by repeatedly grouping together like observations in the training data. We can make predictions for a new case, by tracing it through the tree, and averaging responses of training cases in the same terminal node.</p>
<p><strong>Decision Tree Example:</strong></p>
<p>We fit a decision tree to the Ames Housing dataset, using the <code>rpart</code> function in a package by the same name.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(SalePrice <span class="sc">~</span>., <span class="at">data=</span>Ames_Train, <span class="at">cp=</span><span class="fl">0.04</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree, <span class="at">box.palette=</span><span class="st">"RdBu"</span>, <span class="at">shadow.col=</span><span class="st">"gray"</span>, <span class="at">nn=</span><span class="cn">TRUE</span>, <span class="at">cex=</span><span class="dv">1</span>, <span class="at">extra=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-49-1.png" class="img-fluid figure-img" width="1056"></p>
</figure>
</div>
</div>
</div>
<p>We see that the houses are first split based on whether or not their overall quality rating was less than 8. Each of the resulting nodes are then split again, using information from other explanatory variables. Each split partitions the data further, so that houses in the same node can be thought of as being similar to one another.</p>
<ul>
<li><p>The predicted price of a House with overall quality 7, and was built in 1995 is $200,000.</p></li>
<li><p>The predicted price of a House overall quality 8 and 1,750 sq. ft. on the first floor is $370,000.</p></li>
</ul>
</section>
<section id="partitioning-in-a-decision-tree" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="partitioning-in-a-decision-tree"><span class="header-section-number">7.4.2</span> Partitioning in A Decision Tree</h3>
<p>For a quantitative response variable, data are split into two nodes so that responses in the same node are as similar as possible, while responses in the different nodes are as different as possible.</p>
<p>Let L and R represent the left and right nodes from a possible split. Let <span class="math inline">\(n_L\)</span> and <span class="math inline">\(n_R\)</span> represent the number of observations in each node, and <span class="math inline">\(\bar{y}_L\)</span> and <span class="math inline">\(\bar{y}_R\)</span> represent the mean of the training data responses in each node.</p>
<p>For each possible split, involving an explanatory variable, we calculate:</p>
<p><span class="math display">\[
\displaystyle\sum_{i=1}^{n_L} (y_i -\bar{y}_L)^2 + \displaystyle\sum_{i=1}^{n_R} (y_i -\bar{y}_R)^2
\]</span></p>
<p>We choose the split that minimizes this quantity.</p>
<p><strong>Partitioning Example</strong></p>
<p>Consider a dataset with two explanatory variables, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, and a response variable <span class="math inline">\(y\)</span>, whose values are shown numerically in the graph.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]
x1    8    2    8    1    8    6    2    5    1     8     4    10     9     8
x2    5    3    1    1    4    3    8    1   10     8     6     5     0     2
y   253   64  258   21  257  203  246  114  331   256   213   406   326   273
   [,15]
x1     6
x2     1
y    155</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-51-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The goal is to split up the data, using information about <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> in a way that makes the <span class="math inline">\(y\)</span> values grouped together as similar as possible.</p>
<p><strong>1. One Possible Split (</strong><span class="math inline">\(x_1 &lt; 5.5\)</span>)</p>
<p>We could split the data into 2 groups depending on whether <span class="math inline">\(x_1 &lt; 5.5\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-52-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>We calcuate the mean y-value in each resulting node:</p>
<ul>
<li><span class="math inline">\(\bar{y}_L = (331+246+213+21+64+114)/6 \approx 164.84\)</span><br>
</li>
<li><span class="math inline">\(\bar{y}_R = (203+155+256+253+257+273+258+326+406)/9 \approx 265.22\)</span></li>
</ul>
<p>To measure measure the amount of deviation in the node, we calculate the sum of the squared difference between each individual value and the overall mean in each node.</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \displaystyle\sum_{i=1}^{n_L} (y_i -\bar{y}_L)^2  \\
&amp; =(331-164.83)^2+(246-164.33)^2 + \ldots+(114-164.33)^2 \\
&amp; =69958.83
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\displaystyle\sum_{i=1}^{n_R} (y_i -\bar{y}_R)^2 \\
&amp; =(203-265.22)^2+(155-265.22)^2 + \ldots+(406-265.22)^2 \\
&amp; =39947.56
\end{aligned}
\]</span></p>
<p>Adding together these two quantities, we obtain an overall measure of the squared deviations between observations in the same node.</p>
<ul>
<li>69958.83 + 39947.56 = 109906.4</li>
</ul>
<p><strong>2.Second Possible Split (</strong><span class="math inline">\(x_1 &lt; 6.5\)</span>)</p>
<p>We could alternatively split the data into 2 groups depending on whether <span class="math inline">\(x_1 &lt; 6.5\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-53-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>Using this split,</p>
<ul>
<li><span class="math inline">\(\bar{y}_L = (331+246+213+21+64+114 + 203+155)/8 \approx 168.375\)</span><br>
</li>
<li><span class="math inline">\(\bar{y}_R = (256+253+257+273+258+326+406)/7 \approx 289.857\)</span></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; \displaystyle\sum_{i=1}^{n_L} (y_i -\bar{y}_L)^2  \\
&amp; =(331-168.375)^2+(246-168.375)^2 + \ldots+(203-168.375)^2 \\
&amp; =71411.88
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\displaystyle\sum_{i=1}^{n_R} (y_i -\bar{y}_R)^2 \\
&amp; =(203-289.857)^2+(155-289.857)^2 + \ldots+(406-289.857)^2 \\
&amp; =19678.86
\end{aligned}
\]</span></p>
<p>The total squared deviation is:</p>
<ul>
<li>71411.88 + 19678.86 = 91090.74</li>
</ul>
<p>The split at <span class="math inline">\(x1 &lt; 6.5\)</span> is better than <span class="math inline">\(x_1&lt;5.5\)</span></p>
<p><strong>3. Third Possible Split (</strong><span class="math inline">\(x_2 &lt; 5.5\)</span>)</p>
<p>We could also split the data into 2 groups depending on whether <span class="math inline">\(x_2 &lt; 5.5\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-54-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>Using this split,</p>
<ul>
<li><span class="math inline">\(\bar{y}_L = (331+246+213+256)/4 \approx 261.5\)</span><br>
</li>
<li><span class="math inline">\(\bar{y}_R = (21 + 64 + \ldots + 406)/11 \approx 211.82\)</span></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; \displaystyle\sum_{i=1}^{n_L} (y_i -\bar{y}_L)^2  \\
&amp; =(331-261.5)^2+(246-261.5)^2 + (213-261.5)^2+(256-261.5)^2 \\
&amp; =7453
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\displaystyle\sum_{i=1}^{n_R} (y_i -\bar{y}_R)^2 \\
&amp; =(21-211.82)^2+(64-211.82)^2 + \ldots+(406-211.82)^2 \\
&amp; =131493.6
\end{aligned}
\]</span></p>
<p>The sum of squared deviations is:</p>
<ul>
<li>7453 + 131493.6 = 138946.6</li>
</ul>
<p><strong>Comparison of Splits</strong></p>
<ul>
<li><p>Of the three split’s we’ve calculated, <span class="math inline">\(\displaystyle\sum_{i=1}^{n_L} (y_i -\bar{y}_L)^2 + \displaystyle\sum_{i=1}^{n_R} (y_i -\bar{y}_R)^2\)</span> is minimized using <span class="math inline">\(x_1 &lt; 6.5\)</span>.</p></li>
<li><p>In fact, if we calculate all possible splits over <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, <span class="math inline">\(\displaystyle\sum_{i=1}^{n_L} (y_i -\bar{y}_L)^2 + \displaystyle\sum_{i=1}^{n_R} (y_i -\bar{y}_R)^2\)</span> is minimized by splitting on <span class="math inline">\(x_1 &lt; 6.5\)</span></p></li>
</ul>
<p>Thus, we perform the first split in the tree, using <span class="math inline">\(x_1 &lt; 6.5\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-55-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-56-1.png" class="img-fluid figure-img" width="1056"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="next-splits" class="level3" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="next-splits"><span class="header-section-number">7.4.3</span> Next Splits</h3>
<p>Next, we find the best splits on the resulting two nodes. It turns out that the left node is best split on <span class="math inline">\(x_2 &lt; 4.5\)</span>, and the right node is best split on <span class="math inline">\(x_1 &lt; 8.5\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-57-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-58-1.png" class="img-fluid figure-img" width="1056"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="recursive-partitioning" class="level3" data-number="7.4.4">
<h3 data-number="7.4.4" class="anchored" data-anchor-id="recursive-partitioning"><span class="header-section-number">7.4.4</span> Recursive Partitioning</h3>
<p>Splitting continues until nodes reach a certain predetermined minimal size, or until change improvement in model fit drops below a predetermined value</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-59-1.png" class="img-fluid figure-img" width="1056"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="model-complexity-in-trees" class="level3" data-number="7.4.5">
<h3 data-number="7.4.5" class="anchored" data-anchor-id="model-complexity-in-trees"><span class="header-section-number">7.4.5</span> Model Complexity in Trees</h3>
<p>The more we partition data into smaller nodes, the more complex the model becomes. As we continue to partition, bias decreases, as cases are grouped with those that are more similar to themselves. On the other hand, variance increases, as there are fewer cases in each node to be averaged, putting more weight on each individual observation.</p>
<p>Splitting into too small of nodes can lead to drastic overfitting. In the extreme case, if we split all the way to nodes of size 1, we would get RMSE of 0 on the training data, but should certainly not expect RMSPE of 0 on the test data.</p>
<p>The optimal depth of the tree, or minimal size for terminal nodes can be determined using cross-validation. The <code>rpart</code> package uses a complexity parameter <code>cp</code>, which determines how much a split must improve model fit in order to be made. Smaller values of <code>cp</code> are associated with more complex tree models, since they allow splits even when model fit only improves by a little.</p>
</section>
<section id="cross-validation-on-housing-data" class="level3" data-number="7.4.6">
<h3 data-number="7.4.6" class="anchored" data-anchor-id="cross-validation-on-housing-data"><span class="header-section-number">7.4.6</span> Cross-Validation on Housing Data</h3>
<p>We’ll use <code>caret</code> to determine the optimal value of the <code>cp</code> parameter. We use <code>method="rpart"</code> to grow decision trees.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>cp_vals <span class="ot">=</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">100</span>) <span class="co"># test values between 1/10^8 and 1</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(Ames_Train_sc) <span class="ot">&lt;-</span> <span class="fu">make.names</span>(<span class="fu">colnames</span>(Ames_Train_sc))</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11162020</span>)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>Housing_Tree <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train_sc, SalePrice <span class="sc">~</span> .,  <span class="at">method=</span><span class="st">"rpart"</span>, <span class="at">trControl=</span>control, </span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>                     <span class="at">tuneGrid=</span><span class="fu">expand.grid</span>(<span class="at">cp=</span>cp_vals))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The optimal value of <code>cp</code> is:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>Housing_Tree<span class="sc">$</span>bestTune</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             cp
52 0.0004328761</code></pre>
</div>
</div>
<p>We plot RMSPE on the holdout data as a function of <code>cp</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>cp <span class="ot">&lt;-</span> Housing_Tree<span class="sc">$</span>results<span class="sc">$</span>cp</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>RMSPE <span class="ot">&lt;-</span> Housing_Tree<span class="sc">$</span>results<span class="sc">$</span>RMSE</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span><span class="fu">data.frame</span>(cp, RMSPE), <span class="fu">aes</span>(<span class="at">x=</span>cp, <span class="at">y=</span>RMSPE))<span class="sc">+</span><span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.001</span>)) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="fl">0.475</span>,<span class="fl">0.485</span>))  <span class="sc">+</span> </span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Regression Tree Cross Validation Results"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-62-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comparing-ols-lasso-ridge-and-tree" class="level3" data-number="7.4.7">
<h3 data-number="7.4.7" class="anchored" data-anchor-id="comparing-ols-lasso-ridge-and-tree"><span class="header-section-number">7.4.7</span> Comparing OLS, Lasso, Ridge, and Tree</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11162020</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>Housing_OLS <span class="ot">&lt;-</span> <span class="fu">train</span>(<span class="at">data=</span>Ames_Train_sc, SalePrice <span class="sc">~</span> .,  <span class="at">method=</span><span class="st">"lm"</span>, <span class="at">trControl=</span>control)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11162020</span>)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>Housing_lasso <span class="ot">&lt;-</span> <span class="fu">train</span>(SalePrice <span class="sc">~</span>., <span class="at">data =</span> Ames_Train_sc, <span class="at">method =</span> <span class="st">"glmnet"</span>, <span class="at">trControl=</span>control, <span class="at">tuneGrid=</span><span class="fu">expand.grid</span>(<span class="at">alpha=</span><span class="dv">1</span>, <span class="at">lambda=</span>l_vals))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>RMSPE on the standardized version of the response variable is displayed below for ordinary least squares, ridge regression, lasso regression, and a decision tree.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(Housing_OLS <span class="sc">$</span>results<span class="sc">$</span>RMSE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5612835</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(Housing_ridge<span class="sc">$</span>results<span class="sc">$</span>RMSE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4552125</code></pre>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(Housing_lasso<span class="sc">$</span>results<span class="sc">$</span>RMSE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4764163</code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(Housing_Tree<span class="sc">$</span>results<span class="sc">$</span>RMSE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.477414</code></pre>
</div>
</div>
<p>In this situation, the tree outperforms OLS, but does not do as well as the ridge regression model. The best model will vary depending on the nature of the data. We can use cross-validation to determine which model is likely to perform best in prediction.</p>
</section>
<section id="random-forest" class="level3" data-number="7.4.8">
<h3 data-number="7.4.8" class="anchored" data-anchor-id="random-forest"><span class="header-section-number">7.4.8</span> Random Forest</h3>
<p>A popular extension of a decision tree is a random forest. A random forest consists of many (often ~10,000) trees. Predictions are made by averaging predictions from individual trees.</p>
<ul>
<li>In order to ensure the trees are different from each other:
<ol type="1">
<li>each tree is grown from a different bootstrap sample of the training data.<br>
</li>
<li>when deciding on a split, only a random subset of explanatory variables are considered.</li>
</ol></li>
</ul>
<p>Growing deep trees ensures low bias. In a random forest, averaging across many deep trees decreases variance, while maintaining low bias.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="regression-splines" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="regression-splines"><span class="header-section-number">7.5</span> Regression Splines</h2>
<section id="regression-splines-1" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="regression-splines-1"><span class="header-section-number">7.5.1</span> Regression Splines</h3>
<p>We’ve seen that we can use polynomial regression to capture nonlinear trends in data.</p>
<ul>
<li>A <strong>regression spline</strong> is a piecewise function of polynomials.</li>
</ul>
<p>Here we’ll keep thing simple by focusing on a spline with a single explanatory variable. Splines can also be used for multivariate data.</p>
<p>We’ll examine the use of splines on the car price prediction dataset.</p>
<p>We divide the data into a set of 75 cars, which we’ll use to train the model, and 35 cars, on which we’ll make and evaluate predictions.</p>
<p>The 75 cars in the training set are shown below.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-66-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="two-models-with-high-bias" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="two-models-with-high-bias"><span class="header-section-number">7.5.2</span> Two Models with High Bias</h3>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-67-1.png" class="img-fluid figure-img" width="1152"></p>
</figure>
</div>
</div>
</div>
<p>The constant and linear models have high bias, as they are not complex enough to capture the apparent curvature in the relationship between price and acceleration time.</p>
<p>A cubic model, on the other hand might better capture the trend.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-68-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="cubic-splines" class="level3" data-number="7.5.3">
<h3 data-number="7.5.3" class="anchored" data-anchor-id="cubic-splines"><span class="header-section-number">7.5.3</span> Cubic Splines</h3>
<p>It’s possible that the behavior of the response variable might differ in different regions of the x-axis. A cubic spline allows us to fit different models in different regions of the x-axis.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-69-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p>The region boundaries are called <strong>knots</strong></p>
<p><strong>Cubic Spline with 5 Knots</strong></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-70-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p><strong>Cubic Spline with 10 Knots</strong></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-71-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p><strong>Cubic Spline with 20 Knots</strong></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-72-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p>Notice that as the number of knots increases, the model becomes more and more complex. We would not expect the relationship between price and acceleration time to look like it does in these more complicated pictures. It is likely that as the number of knots gets big, the model overfits the training data.</p>
</section>
<section id="predicting-test-data" class="level3" data-number="7.5.4">
<h3 data-number="7.5.4" class="anchored" data-anchor-id="predicting-test-data"><span class="header-section-number">7.5.4</span> Predicting Test Data</h3>
<p>Shown below is a plot of RMSPE when predictions are made on the new test data.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-73-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p>We see that RMSPE is minimized using the model with three knots.</p>
</section>
<section id="implementation-of-splines" class="level3" data-number="7.5.5">
<h3 data-number="7.5.5" class="anchored" data-anchor-id="implementation-of-splines"><span class="header-section-number">7.5.5</span> Implementation of Splines</h3>
<p>Important Considerations:</p>
<ul>
<li>how many knots<br>
</li>
<li>where to place knots<br>
</li>
<li>degree of polynomial</li>
</ul>
<p>The best choices for all of these will vary between datasets and can be assessed through cross-validation.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="assessing-a-classifiers-performance" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="assessing-a-classifiers-performance"><span class="header-section-number">7.6</span> Assessing a Classifier’s Performance</h2>
<section id="measuring-prediction-accuracy" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="measuring-prediction-accuracy"><span class="header-section-number">7.6.1</span> Measuring Prediction Accuracy</h3>
<p>Just as we’ve done for models with quantitative variables, we’ll want to compare and assess the performance of models for predicting categorical responses. This might involve comparing llogistic regression models with different explanatory variables, or comparing a regression model to another technique such as a decision tree.</p>
<p>Just as we did before, we’ll divide the data so that we can evaluate predictions on a subset of the data that was not used to fit the model.</p>
<p>We’ll divide the credit card dataset into a set of 9,000 observations, on which we’ll fit our models and assess predictions on the remaining 1,000.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">08172022</span>)</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Default)</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>samp <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Default), <span class="dv">1000</span>)</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>Default_Test <span class="ot">&lt;-</span> Default[samp, ]</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>Default_Train <span class="ot">&lt;-</span> Default[<span class="sc">-</span>samp, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We fit the model with interaction to the training data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>LR_Default_M_Int <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="at">data=</span>Default_Train, default <span class="sc">~</span> balance <span class="sc">*</span> student, <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>))</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(LR_Default_M_Int)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ balance * student, family = binomial(link = "logit"), 
    data = Default_Train)

Coefficients:
                      Estimate  Std. Error z value            Pr(&gt;|z|)    
(Intercept)        -11.2714061   0.5188284 -21.725 &lt;0.0000000000000002 ***
balance              0.0060696   0.0003273  18.547 &lt;0.0000000000000002 ***
studentYes           0.0924588   0.8606304   0.107               0.914    
balance:studentYes  -0.0004749   0.0005142  -0.924               0.356    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2617.1  on 8999  degrees of freedom
Residual deviance: 1385.5  on 8996  degrees of freedom
AIC: 1393.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<p>We then use the model to estimate the probability of a person defaulting on their credit card payment.</p>
<p>Information about 10 different credit card users, as well as the logistic regression estimate of their probability of default are shown below. The table also shows whether or not the user really defaulted on their payment.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>LR_Prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(LR_Default_M_Int, <span class="at">newdata=</span>Default_Test, <span class="at">type=</span><span class="st">"response"</span>) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>Actual_Default <span class="ot">&lt;-</span> Default_Test<span class="sc">$</span>default <span class="co">#factor(ifelse(Default_Test$default==1, "Yes", "No"))</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>student <span class="ot">&lt;-</span> Default_Test<span class="sc">$</span>student</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>balance <span class="ot">&lt;-</span> Default_Test<span class="sc">$</span>balance</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>LR_Res_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(student, balance, LR_Prob, Actual_Default)</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(<span class="fu">head</span>(LR_Res_df, <span class="dv">50</span>)<span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(LR_Prob)) <span class="sc">%&gt;%</span> <span class="fu">head</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">student</th>
<th style="text-align: right;">balance</th>
<th style="text-align: right;">LR_Prob</th>
<th style="text-align: left;">Actual_Default</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2465</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">2026.864</td>
<td style="text-align: right;">0.54</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">1228</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1682.201</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">6656</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1551.028</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">1185</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1541.813</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9963</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1635.175</td>
<td style="text-align: right;">0.12</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">6635</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1434.128</td>
<td style="text-align: right;">0.07</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9691</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1391.318</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">5921</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1513.542</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9755</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1233.619</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">7569</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1294.286</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="decision-tree-classifier" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="decision-tree-classifier"><span class="header-section-number">7.6.2</span> Decision Tree Classifier</h3>
<p>For comparison, let’s use a decision tree to predict whether a person will default.</p>
<p>In a binary classification problem, we can treat a default as <span class="math inline">\(y=1\)</span> and non-default as <span class="math inline">\(y=0\)</span>, and grow the tree as we would in regression.</p>
<p>The mean response in a node <span class="math inline">\(\bar{Y}\)</span>, which is equivalent to the proportion of people in the node who defaulted, can be interpreted as the probability of default.</p>
<p>The first few splits of the tree are shown.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co"># grow shorter tree for illustration</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(<span class="at">data=</span>Default_Train, default<span class="sc">~</span>balance <span class="sc">+</span> student, <span class="at">cp=</span><span class="fl">0.005</span>)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree, <span class="at">box.palette=</span><span class="st">"RdBu"</span>, <span class="at">shadow.col=</span><span class="st">"gray"</span>, <span class="at">nn=</span><span class="cn">TRUE</span>, <span class="at">cex=</span><span class="dv">1</span>, <span class="at">extra=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-77-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># grow full tree</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(<span class="at">data=</span>Default_Train, default<span class="sc">~</span>balance <span class="sc">+</span> student)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>Tree_Prob <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree, <span class="at">newdata =</span> Default_Test)[,<span class="dv">2</span>] <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We add the decision tree probabilities to the table seen previously.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>LR_Res_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(student, balance, LR_Prob, Tree_Prob, Actual_Default)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(<span class="fu">head</span>(LR_Res_df, <span class="dv">50</span>)<span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(LR_Prob)) <span class="sc">%&gt;%</span> <span class="fu">head</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">student</th>
<th style="text-align: right;">balance</th>
<th style="text-align: right;">LR_Prob</th>
<th style="text-align: right;">Tree_Prob</th>
<th style="text-align: left;">Actual_Default</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2465</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">2026.864</td>
<td style="text-align: right;">0.54</td>
<td style="text-align: right;">0.77</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">1228</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1682.201</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">6656</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1551.028</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">1185</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1541.813</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9963</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1635.175</td>
<td style="text-align: right;">0.12</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">6635</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1434.128</td>
<td style="text-align: right;">0.07</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9691</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1391.318</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">5921</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1513.542</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9755</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1233.619</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">7569</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1294.286</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We see that the tree estimates that the first person has a 0.77 probability of defaulting on the payment, compared to an estimate of 0.54, given by the logistic regression model. On the other hand, the tree estimates only a 0.16 probability of the second person defaulting, compared to 0.26 for the logistic regression model.</p>
</section>
<section id="assessing-classifier-accuracy" class="level3" data-number="7.6.3">
<h3 data-number="7.6.3" class="anchored" data-anchor-id="assessing-classifier-accuracy"><span class="header-section-number">7.6.3</span> Assessing Classifier Accuracy</h3>
<p>We’ve seen <span class="math inline">\(\text{RMSPE} = \sqrt{\displaystyle\sum_{i=1}^{n}{(\hat{y}_i-y_i)^2}}\)</span> used as a measure of predictive accuracy in a regression problem.</p>
<p>Since our outcome is not numeric, this is not a good measure of predictive accuracy in a classification problem. We’ll examine some alternatives we can use instead.</p>
<p><strong>Classification Accuracy</strong></p>
<p>One simple approach is calculate the proportion of credit card users classified correctly. If a person has model estimates a predicted probability of default greater than 0.5, the person is predicted to default, while if the probability estimate is less than 0.5, the person is predicted to not default.</p>
<p>The table shows the prediction for each of the 10 users, using both logistic regression and the decision tree.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>LR_Pred <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(LR_Prob <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>))</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>Tree_Pred <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(Tree_Prob <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"Yes"</span>, <span class="st">"No"</span>))</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>LR_Res_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(student, balance, LR_Prob, Tree_Prob, LR_Pred,Tree_Pred, Actual_Default)</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(<span class="fu">head</span>(LR_Res_df, <span class="dv">50</span>)<span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(LR_Prob)) <span class="sc">%&gt;%</span> <span class="fu">head</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 6%">
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">student</th>
<th style="text-align: right;">balance</th>
<th style="text-align: right;">LR_Prob</th>
<th style="text-align: right;">Tree_Prob</th>
<th style="text-align: left;">LR_Pred</th>
<th style="text-align: left;">Tree_Pred</th>
<th style="text-align: left;">Actual_Default</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2465</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">2026.864</td>
<td style="text-align: right;">0.54</td>
<td style="text-align: right;">0.77</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">1228</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1682.201</td>
<td style="text-align: right;">0.26</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">6656</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1551.028</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">1185</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1541.813</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9963</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1635.175</td>
<td style="text-align: right;">0.12</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">6635</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1434.128</td>
<td style="text-align: right;">0.07</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9691</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1391.318</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">5921</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1513.542</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9755</td>
<td style="text-align: left;">No</td>
<td style="text-align: right;">1233.619</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
<tr class="even">
<td style="text-align: left;">7569</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: right;">1294.286</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: right;">0.02</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">No</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Notice that although the probabilities differ, the logistic regression model and classification tree give the same predictions for these ten cases. Both correctly predict 8 out of the 10 cases, but mistakenly predict the first person to default, when they didn’t, and mistakenly predict that the sixth person would not default when they did.</p>
<p>We’ll check the classification accuracy for the model and the tree.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>base<span class="sc">::</span><span class="fu">sum</span>(LR_Pred <span class="sc">==</span> Actual_Default)<span class="sc">/</span><span class="dv">1000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.972</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>base<span class="sc">::</span><span class="fu">sum</span>(Tree_Pred <span class="sc">==</span> Actual_Default)<span class="sc">/</span><span class="dv">1000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.97</code></pre>
</div>
</div>
<p>We see that the two techniques are each right approximately 97% of the time.</p>
<p>This may not really be as good as it sounds. Can you think of a very simple classification strategy that would achieve a similarly impressive predictive accuracy on these data?</p>
</section>
<section id="confusion-matrix" class="level3" data-number="7.6.4">
<h3 data-number="7.6.4" class="anchored" data-anchor-id="confusion-matrix"><span class="header-section-number">7.6.4</span> Confusion Matrix</h3>
<p>In addition to assessing overall accuracy, it is sometimes helpful to assess how well models are able to predict outcomes in each class. For example, how accurately can a model detect people who do actually default on their payments?</p>
<p>A <strong>confusion matrix</strong> is a two-by-two table displaying the number of cases predicted in each category as columns, and the number of cases actually in each category as rows</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>Actually Negative</th>
<th>Actually Positive</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Predicted Negative</td>
<td># True Negative</td>
<td># False Negative</td>
</tr>
<tr class="even">
<td>Predicted Positive</td>
<td># False Positive</td>
<td># True Positive</td>
</tr>
</tbody>
</table>
<p>The <code>confusionMatrix</code> matrix command in R returns the confusion matrix for all 1,000 test cases.</p>
<p>Let’s look at the confusion matrix for all 1,000 test cases. The <code>data</code> argument is the predicted outcome, and the <code>reference</code> argument is the true outcome. The <code>positive</code> argument is the category that we’ll classify as a positive.</p>
<p><strong>Logistic Regression Confusion Matrix</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">data=</span>LR_Pred, <span class="at">reference=</span><span class="fu">factor</span>(Actual_Default) , <span class="at">positive=</span><span class="st">"Yes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  No Yes
       No  957  20
       Yes   8  15
                                          
               Accuracy : 0.972           
                 95% CI : (0.9598, 0.9813)
    No Information Rate : 0.965           
    P-Value [Acc &gt; NIR] : 0.12988         
                                          
                  Kappa : 0.5035          
                                          
 Mcnemar's Test P-Value : 0.03764         
                                          
            Sensitivity : 0.4286          
            Specificity : 0.9917          
         Pos Pred Value : 0.6522          
         Neg Pred Value : 0.9795          
             Prevalence : 0.0350          
         Detection Rate : 0.0150          
   Detection Prevalence : 0.0230          
      Balanced Accuracy : 0.7101          
                                          
       'Positive' Class : Yes             
                                          </code></pre>
</div>
</div>
<p>Out of 965 people who did not default, the logistic regression model correctly predicted 957 of them.</p>
<p>Out of 35 people that did default, the model correctly predicted 15 of them.</p>
<p><strong>Tree Confusion Matrix</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data is predicted class</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="co"># reference is actual class</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>( <span class="at">data =</span> Tree_Pred , <span class="at">reference=</span> Actual_Default, <span class="st">"Yes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  No Yes
       No  954  19
       Yes  11  16
                                          
               Accuracy : 0.97            
                 95% CI : (0.9574, 0.9797)
    No Information Rate : 0.965           
    P-Value [Acc &gt; NIR] : 0.2225          
                                          
                  Kappa : 0.5009          
                                          
 Mcnemar's Test P-Value : 0.2012          
                                          
            Sensitivity : 0.4571          
            Specificity : 0.9886          
         Pos Pred Value : 0.5926          
         Neg Pred Value : 0.9805          
             Prevalence : 0.0350          
         Detection Rate : 0.0160          
   Detection Prevalence : 0.0270          
      Balanced Accuracy : 0.7229          
                                          
       'Positive' Class : Yes             
                                          </code></pre>
</div>
</div>
<p>Out of 965 people who did not default, the logistic regression model correctly predicted 960 of them.</p>
<p>Out of 35 people that did default, the model correctly predicted 11 of them.</p>
<p>Notice that the tree was less likely to predict a person to default in general, returning only 16 positive predictions, compared to 23 for the logistic regression model.</p>
</section>
<section id="sensitivity-and-specificity" class="level3" data-number="7.6.5">
<h3 data-number="7.6.5" class="anchored" data-anchor-id="sensitivity-and-specificity"><span class="header-section-number">7.6.5</span> Sensitivity and Specificity</h3>
<p>The <strong>sensitivity</strong> of a classifier is the proportion of all positive cases that the model correctly identifies as positive. (i.e.&nbsp;probability model says “positive” given actually is positive.)</p>
<p><span class="math display">\[
\text{Sensitivity} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Negative}} = \frac{\text{Correctly Predicted Positives}}{\text{Total Number of Actual Positives}}
\]</span></p>
<p><strong>LR Sensitivity</strong></p>
<p><span class="math display">\[
\frac{15}{15+20} \approx 0.4286
\]</span></p>
<p><strong>Tree Sensitivity</strong></p>
<p><span class="math display">\[
\frac{11}{11+24} \approx 0.3143
\]</span></p>
<p>The <strong>specificity</strong> of a classifier is the proportion of all negative cases that the model correctly identifies as negative (i.e probabiltiy model says “negative” given truly is negative.)</p>
<p><span class="math display">\[\text{Specificity} = \frac{\text{True Negative}}{\text{True Negative} + \text{False Positive}}= \frac{\text{Correctly Predicted Negatives}}{\text{Total Number of Actual Negatives}}
\]</span></p>
<p><strong>LR Specificity</strong></p>
<p><span class="math display">\[\frac{957}{957+8} \approx 0.9917\]</span></p>
<p><strong>Tree Specificity</strong></p>
<p><span class="math display">\[\frac{960}{960+5} \approx 0.9948 \]</span></p>
<p>In a given situation, we should think about the cost of a false negative vs a false positive when determining whether to place more weight on sensitivity or specificity. For example, “is it worse to tell a patient they tested positive for a disease when they really don’t have it, or to not tell them they tested positive when they really do have it?”</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="receiver-operating-characteristic-curve" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="receiver-operating-characteristic-curve"><span class="header-section-number">7.7</span> Receiver Operating Characteristic Curve</h2>
<section id="separating-s-and--s" class="level3" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="separating-s-and--s"><span class="header-section-number">7.7.1</span> Separating +’s and -’s</h3>
<p>The prediction accuracy, sensitivity, and specificity measures, seen in the previous section are based only on the predicted outcome, without considering the probability estimates themselves. These techniques treat a 0.49 estimated probability of default the same as a 0.01 estimated probability.</p>
<p>We would hope to see more defaults among people with high estimated default probabilities than low ones. To assess this, we can list the people in order from highest to lowest probability estimates and see where the true defaults lie.</p>
<p>For example, consider the following fictional probability estimates produced by two different classifiers (models) for eight credit card users:</p>
<p><strong>Classifier 1</strong></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  Classifier1_Probability_Estimate True_Outcome
1                             0.90          Yes
2                             0.75          Yes
3                             0.60           No
4                             0.40          Yes
5                             0.30           No
6                             0.15           No
7                             0.05           No
8                             0.01           No</code></pre>
</div>
</div>
<p><strong>Classifier 2</strong></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>  Classifier2_Probability_Estimate True_Outcome
1                             0.80          Yes
2                             0.70           No
3                             0.55           No
4                             0.40          Yes
5                             0.35           No
6                             0.15           No
7                             0.10          Yes
8                             0.02           No</code></pre>
</div>
</div>
<p>Classifier 1 is better able to separate the “Yes’s” from “No’s” as the three true “Yes’s” are among the four highest probabilities. Classifier 2 is less able to separate the true “Yes’s” from true “No’s.”</p>
</section>
<section id="roc-curve" class="level3" data-number="7.7.2">
<h3 data-number="7.7.2" class="anchored" data-anchor-id="roc-curve"><span class="header-section-number">7.7.2</span> ROC Curve</h3>
<p>A receiver operating characteristic (ROC) curve tells us how well a predictor is able to separate positive cases from negative cases.</p>
<p>The blog (Toward Data Science) [https://towardsdatascience.com/applications-of-different-parts-of-an-roc-curve-b534b1aafb68] writes</p>
<p>“Receiver Operating Characteristic (ROC) curve is one of the most common graphical tools to diagnose the ability of a binary classifier, independent of the inherent classification algorithm. The ROC analysis has been used in many fields including medicine, radiology, biometrics, natural hazards forecasting, meteorology, model performance assessment, and other areas for many decades and is increasingly used in machine learning and data mining research [1]. If you are a Data Scientist, you might be using it on a daily basis.”</p>
<p>The ROC curve plots the true positive (or hit) rate against the false positive rate (false alarm) rate, as the cutoff for a positive classification varies.</p>
<div class="cell" data-caption="Image from Wikipedia">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Roc_Curve.png" class="img-fluid figure-img" style="width:75.0%"></p>
</figure>
</div>
</div>
</div>
<p>The higher the curve, the better the predictor is able to separate positive cases from negative ones.</p>
<p>Predictions made totally at random would be expected to yield a diagonal ROC curve.</p>
</section>
<section id="constructing-roc-curve" class="level3" data-number="7.7.3">
<h3 data-number="7.7.3" class="anchored" data-anchor-id="constructing-roc-curve"><span class="header-section-number">7.7.3</span> Constructing ROC Curve</h3>
<ol type="1">
<li>Order the probabilities from highest to lowest.<br>
</li>
<li>Assume only the case with the highest probability is predicted as a positive.<br>
</li>
<li>Calculate the true positive rate (hit rate) <span class="math display">\[\frac{\text{\# True Positives}}{\text{\# Actual Positives}}\]</span> and false positive (false alarm) <span class="math display">\[\frac{\text{\# False Positives}}{\text{\# Actual Negatives}}\]</span>rate.</li>
<li>Plot the point <span class="math display">\[\left( \frac{\text{\# False Positives}}{\text{\# Actual Negatives}}, \frac{\text{\# True Positives}}{\text{\# Actual Positives}} \right)\]</span> in the coordinate plane.<br>
</li>
<li>Now assume the cases with the two highest probabilities are predicted as positives, and repeat steps 3-4.<br>
</li>
<li>Continue, by classifiying one more case as positive in each step.</li>
</ol>
</section>
<section id="construct-roc-example" class="level3" data-number="7.7.4">
<h3 data-number="7.7.4" class="anchored" data-anchor-id="construct-roc-example"><span class="header-section-number">7.7.4</span> Construct ROC Example</h3>
<p>Let’s practice constructing an ROC curve for a small set of probability estimates.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>prob <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.8</span>, <span class="fl">0.7</span>, <span class="fl">0.65</span>, <span class="fl">0.45</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span>, <span class="fl">0.15</span>, <span class="fl">0.1</span>, <span class="fl">0.05</span>)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>Actual <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"+"</span>, <span class="st">"-"</span>, <span class="st">"+"</span>, <span class="st">"+"</span>, <span class="st">"-"</span>, <span class="st">"-"</span>, <span class="st">"-"</span>, <span class="st">"-"</span>, <span class="st">"+"</span>, <span class="st">"-"</span>)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>Hit_Rate <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"1/4"</span>, <span class="st">"1/4"</span>, <span class="st">"2/4"</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>FA_Rate <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"0/6"</span>, <span class="st">"1/6"</span>, <span class="st">"1/6"</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>, <span class="st">""</span>)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(<span class="fu">data.frame</span>(prob, Actual, Hit_Rate, FA_Rate))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">prob</th>
<th style="text-align: left;">Actual</th>
<th style="text-align: left;">Hit_Rate</th>
<th style="text-align: left;">FA_Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.90</td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">1/4</td>
<td style="text-align: left;">0/6</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.80</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">1/4</td>
<td style="text-align: left;">1/6</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.70</td>
<td style="text-align: left;">+</td>
<td style="text-align: left;">2/4</td>
<td style="text-align: left;">1/6</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.65</td>
<td style="text-align: left;">+</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.45</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">0.30</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.20</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">0.15</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: right;">0.10</td>
<td style="text-align: left;">+</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">0.05</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Finish filling in the table and sketch a graph of the resulting ROC curve.</p>
<p><strong>Question:</strong> If the probability estimate of 0.45 were instead 0.5 or 0.55, would this change the ROC curve? Why or why not?</p>
</section>
<section id="auc" class="level3" data-number="7.7.5">
<h3 data-number="7.7.5" class="anchored" data-anchor-id="auc"><span class="header-section-number">7.7.5</span> AUC</h3>
<p>The area under the ROC curve, (AUC) provides a measure of the model’s predictive strength.</p>
<p>While there is no standard for what constitutes a <code>good" AUC, higher is better, and</code>AUC” is useful for comparing models.</p>
<p>A model that can perfectly separate successes from failures will have an AUC of 1.</p>
<p>A model that assigns probabilities at random is expected to have an AUC of 0.5.</p>
</section>
<section id="lr-and-tree-roc-curves" class="level3" data-number="7.7.6">
<h3 data-number="7.7.6" class="anchored" data-anchor-id="lr-and-tree-roc-curves"><span class="header-section-number">7.7.6</span> LR and Tree ROC Curves</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(verification)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="fu">roc.plot</span>(<span class="at">x=</span>Default_Test<span class="sc">$</span>default<span class="sc">==</span><span class="st">"Yes"</span>, <span class="at">pred =</span> LR_Prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-90-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">auc</span>(<span class="at">response=</span>Default_Test<span class="sc">$</span>default<span class="sc">==</span><span class="st">"Yes"</span>, <span class="at">predictor =</span> LR_Prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Area under the curve: 0.8953</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">roc.plot</span>(<span class="at">x=</span>Default_Test<span class="sc">$</span>default<span class="sc">==</span><span class="st">"Yes"</span>, <span class="at">pred =</span> Tree_Prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-92-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">auc</span>(<span class="at">response=</span>Default_Test<span class="sc">$</span>default<span class="sc">==</span><span class="st">"Yes"</span>, <span class="at">predictor =</span> Tree_Prob)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Area under the curve: 0.75</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>RandProb <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">roc.plot</span>(<span class="at">x=</span>Default_Test<span class="sc">$</span>default<span class="sc">==</span><span class="st">"Yes"</span>, <span class="at">pred =</span> RandProb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Ch7_files/figure-html/unnamed-chunk-95-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">auc</span>(<span class="at">response=</span>Default_Test<span class="sc">$</span>default, <span class="at">predictor =</span> RandProb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Area under the curve: 0.563</code></pre>
</div>
</div>
<p>Even though a model that assigns predictions randomly, with 97% predicted as negatives will have a high accuracy rate, it will yield a poor ROC curve indicating an inability to separate positive cases from negative ones.</p>
<div style="page-break-after: always;"></div>
</section>
</section>
<section id="ethical-considerations-in-predictive-modeling" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="ethical-considerations-in-predictive-modeling"><span class="header-section-number">7.8</span> Ethical Considerations in Predictive Modeling</h2>
<section id="assumptions-in-predictive-models" class="level3" data-number="7.8.1">
<h3 data-number="7.8.1" class="anchored" data-anchor-id="assumptions-in-predictive-models"><span class="header-section-number">7.8.1</span> Assumptions in Predictive Models</h3>
<p>Like any other statistical technique, predictive inference (sometimes done through machine learning algorithms) depends on the validity of assumptions.</p>
<ol type="1">
<li><p>The response variable observed in the data is actually the thing we want to predict<br>
</p></li>
<li><p>Training/Test data representative of population of interest</p></li>
<li><p>Prediction accuracy is appropriate metric</p></li>
</ol>
<p>Below are some examples of real uses of predictive inference in which some of these assumptions were violated, leading to inappropriate and unethical conclusions.</p>
</section>
<section id="amazon-hiring-algorithm" class="level3" data-number="7.8.2">
<h3 data-number="7.8.2" class="anchored" data-anchor-id="amazon-hiring-algorithm"><span class="header-section-number">7.8.2</span> Amazon Hiring Algorithm</h3>
<p>In 2014, Amazon began working on an algorithm to predict whether a job applicant would be suitable for hire for software developer positions, based on characteristics of their job application.</p>
<p>response variable: rating of candidate’s strength (1-5) explanatory variables: many variables based on information included on the resume (e.g.&nbsp;highest degree, major, GPA, college/university, prior job experiences, internships, frequency of certain words on resume, etc.)</p>
<p>The algorithm was trained using data from past applications, rated by humans, over the past 10 years. It could then be used to predict ratings of future job applicants.</p>
<p>According to [Reuters])(https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G),</p>
<p>“In effect, Amazon’s system taught itself that male candidates were preferable. It penalized resumes that included the word “women’s,” as in “women’s chess club captain.” And it downgraded graduates of two all-women’s colleges, according to people familiar with the matter.”</p>
<p>While the algorithm was intended to predict candidate quality, the response variable on the training data actually reflected biases in past hiring decisions, leading the algorithm to do the same.</p>
</section>
<section id="facial-recognition" class="level3" data-number="7.8.3">
<h3 data-number="7.8.3" class="anchored" data-anchor-id="facial-recognition"><span class="header-section-number">7.8.3</span> Facial Recognition</h3>
<p>Facial recognition technology is used by law enforcement surveillance, airport passenger screening, and employment and housing decisions. It has, however, been banned for use by police in some cities, including San Francisco and Boston, due to concerns about inequity and privacy.</p>
<p><a href="https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/">Research</a> has shown that although certain facial recognition algorithms achieve over 90% accuracy overall, accuracy rate is lower among subjects who are female, Black, or 18-30 years old.</p>
<p>This is likely due, at least in part, to the algorithms being trained primarily on data an images of people who are not members of these groups.</p>
<p>Although the algorithms might attain strong accuracy overall, it is inappropriate to evaluate them on this basis, without accounting for performance on subgroups in the population.</p>
</section>
<section id="comments" class="level3" data-number="7.8.4">
<h3 data-number="7.8.4" class="anchored" data-anchor-id="comments"><span class="header-section-number">7.8.4</span> Comments</h3>
<p>The biases and assumptions noted above are not reasons to abandon predictive modeling, but rather flaws to be aware of and work to correct.</p>
<p>Predictive algorithms, are only as good as the data on which they are trained and the societies in which they are developed, and will reflect inherent biases. Thus, they should be used cautiously and with with human judgment, just like any other statistical technique.</p>
<p>Beware of statements like:</p>
<p>“The data say this!”</p>
<p>“The algorithm is objective.”</p>
<p>“The numbers don’t lie.”</p>
<p>Any data-driven analysis depends on assumptions, and sound judgment and awareness of context are required when assessing the validity of conclusions drawn.</p>
</section>
<section id="modeling-for-prediction-1" class="level3" data-number="7.8.5">
<h3 data-number="7.8.5" class="anchored" data-anchor-id="modeling-for-prediction-1"><span class="header-section-number">7.8.5</span> Modeling for Prediction</h3>
<ul>
<li>Goal is to make the most accurate predictions possible.<br>
</li>
<li>Not concerned with understanding relationships between variables. Not worried model being to complicated to interpret, as long as it yields good predictions.<br>
</li>
<li>Aim for a model that best captures the signal in the data, without being thrown off by noise.<br>

<ul>
<li>Large number of predictors is ok<br>
</li>
<li>Don’t make model so complicated that it overfits the data.<br>
</li>
</ul></li>
<li>Be sure that model is predicting what you intend it to<br>
</li>
<li>Reflective of biases inherent in the data on which it was trained</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Ch6.html" class="pagination-link" aria-label="Logistic Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->




</body></html>